{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernandoespinosa/3546-034/blob/master/Assignment%203%20-%20Contextualized%20Word%20Embeddings/SCS_3546_Assignment_03_Fall2022_Fernando_Espinosa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SCS 3546: Deep Learning\n",
        "> **Assignment 3: Contextualized Word Embeddings**"
      ],
      "metadata": {
        "id": "N5vYuxQwmkFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Your name & student number:\n",
        "\n",
        "<pre> Student Name: Fernando Espinosa </pre>\n",
        "\n",
        "<pre> Student Number: X566420 </pre>"
      ],
      "metadata": {
        "id": "b1kme0NkmpLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Assignment Description**\n",
        "***\n",
        "\n",
        "Search Engines are a standard tool for finding relevant content. The calculation of similarity between textual information is an important factor for better search results.\n",
        "\n",
        "### **Objectives**\n",
        "\n",
        "**Your goal in this assignment is to calculate the textual similarity between queries and the provided sample documents, using a variety of NLP approaches.**\n",
        "\n",
        "In achieving the above goal, you will also:\n",
        "- Demonstrate how to preprocess text and embed textual data.\n",
        "- Compare the results of textual similarity scoring between traditional and deep-learning based NLP methods.\n",
        "\n",
        "### **Data and Queries**\n",
        "\n",
        "You will use the document repository provided by `sample_repository.json`, which you can download from the following link, or from the assignment description in Quercus: https://q.utoronto.ca/courses/286389/files/21993451/download?download_frd=1\n",
        "\n",
        "The queries you will run against these sample documents are the following:\n",
        "\n",
        "- Query 1: “fruits”\n",
        "- Query 2: “vegetables”\n",
        "- Query 3: “healthy foods in Canada”\n",
        "\n",
        "### **Techniques to Demonstrate**\n",
        "\n",
        "The techniques you will use to compute the similarity scores are:\n",
        "- 1. TF-IDF.\n",
        "- 2. Semantic similarity using GloVe word vectors.\n",
        "- 3. Semantic similarity using a BERT-based model.\n",
        "\n",
        "\n",
        "### **Feel Free to Choose Your Own Approach**\n",
        "\n",
        "How you go about demonstrating each of the above techniques is up to you. You are not expected to use any particular library. The code below is just meant to provide you with some guidance to get started. You **do**, however, need to demonstrate obtaining similarity scores **with all 3 techniques above**, but how you go about doing this is totally up to you. The evaluation will be based on your ability obtain results using all three techniques, plus your discussion/comparison of any differences you observe.\n",
        "\n"
      ],
      "metadata": {
        "id": "qtPkbEdymrmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Grade Allocation**\n",
        "***\n",
        "15 points total\n",
        "\n",
        "- Experiment 1 (TD-IDF), implementation: 2 marks\n",
        "- Experiment 2 (GloVe), implementation: 3 marks\n",
        "- Experiment 3 (BERT), implementation: 3 marks\n",
        "- Comparison and Discussion: 3 marks\n",
        "  - Compare all three techniques and interpret your findings. Do your best to explain the differences you observe in terms of concepts learned in class (not just the _what_, but also the _how_ and _why_ one technique produces different results from another).\n",
        "- Text Pre-Processing: 2 marks\n",
        " - Cleaning and standardization (e.g. lemmatization, stemming) in Experiment 1\n",
        " - Basic text cleaning (e.g. removal of special characters or tags) in Experiments 2 and 3.\n",
        "- Clarity: 2 marks\n",
        " - The marks for clarity are awarded for code documentation, clean code (e.g. avoiding repetition by building re-usable functions)  and how well you explained/supported your answers, including the use of visualizations.\n"
      ],
      "metadata": {
        "id": "RsGXPLNwm1MK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnvVdcQSiKMA"
      },
      "source": [
        "# Setup and Data Import\n",
        "***\n",
        "You can use the code snippets below to help you load and extract the document repository.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkrMh4W0g4kQ"
      },
      "source": [
        "# you can either drop the file manually into your Colab drive, or otherwise\n",
        "# use this widget to upload it\n",
        "\n",
        "from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VlWbMwpg4u5"
      },
      "source": [
        "# this will unpack the json file contents into a list of titles and documents\n",
        "import json\n",
        "\n",
        "with open('sample_repository.json') as in_file:\n",
        "    repo_data = json.load(in_file)\n",
        "\n",
        "titles = [item[0] for item in repo_data['data']]\n",
        "documents = [item[1] for item in repo_data['data']]\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's take a look at some of these documents and titles;\n",
        "# here we print the five last entries\n",
        "for id in range(-5, 0, 1):\n",
        "  print(f\"Document title: {titles[id]}\")\n",
        "  print(f\"Document contents: {documents[id]}\")\n",
        "  print(\"\\n\") # adds newline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgDwMaKYpdIS",
        "outputId": "e9e3669f-cbc6-456b-baaa-52ac083a46f3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document title: botany\n",
            "Document contents: Botany, also called plant science(s), plant biology or phytology, is the science of plant life and a branch of biology. A botanist, plant scientist or phytologist is a scientist who specialises in this field. \n",
            "\n",
            "\n",
            "Document title: Ford Bronco \n",
            "Document contents: The Ford Bronco is a model line of sport utility vehicles manufactured and marketed by Ford. ... The first SUV model developed by the company, five generations of the Bronco were sold from the 1966 to 1996 model years. A sixth generation of the model line is sold from the 2021 model year. the Ford Bronco will be available in Canada, with first deliveries beginning in spring of 2021. The Bronco will come in six versions in Canada: Base, Big Bend, Black Diamond, Outer Banks, Wildtrak and Badlands. \n",
            "\n",
            "\n",
            "Document title: List of fruit dishes\n",
            "Document contents: Fruit dishes are those that use fruit as a primary ingredient. Condiments prepared with fruit as a primary ingredient are also included in this list.\n",
            "\n",
            "\n",
            "Document title: Neuro linguistic programming\n",
            "Document contents: Neuro linguistic programming (NLP) is a pseudoscientific approach to communication, personal development, and psychotherapy created by Richard Bandler and John Grinder in California, United States, in the 1970s.\n",
            "\n",
            "\n",
            "Document title: fruit serving bowl\n",
            "Document contents: A fruit serving bowl is a round dish or container typically used to prepare and serve food. The interior of a bowl is characteristically shaped like a spherical cap, with the edges and the bottom forming a seamless curve. This makes bowls especially suited for holding liquids and loose food, as the contents of the bowl are naturally concentrated in its center by the force of gravity.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1zBu6DIjdtP"
      },
      "source": [
        "# Experiment 1: TF-IDF\n",
        "***\n",
        "\n",
        "**T**erm **F**requency - **I**nverse **D**ocument **F**requency (TF-IDF) is a traditional NLP technique to look at words that appear in both pieces of text, and score them based on how often they appear. For this experiment, you are free to use the TF-IDF implementation provided by scikit-learn.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XP9_ncYg4yu",
        "outputId": "dc3c29f1-ff03-4e65-8086-f6402b5ac917"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('punkt')\n",
        "stop_words = set(stopwords.words('english'))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f'stop_words: {type(stop_words)}')\n",
        "\n",
        "# need to keep have list to avoid error in TfidfVectorizer() contructor:\n",
        "# InvalidParameterError: The 'stop_words' parameter of TfidfVectorizer must be\n",
        "# a str among {'english'}, an instance of 'list' or None ...\n",
        "\n",
        "stop_words_list = list(stop_words)\n",
        "print(f'stop_words_list: {type(stop_words_list)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB00_LZZzQ16",
        "outputId": "32a99475-3830-4401-e66d-3bcac6ef5dca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stop_words: <class 'set'>\n",
            "stop_words_list: <class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym076HWMg42r"
      },
      "source": [
        "\n",
        "# Calculate the word frequency, and a measure of similarity of the search terms with each document.\n",
        "# Do not apply any text pre-processing (i.e. cleanup) yet.\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def word_frequency_measure_similarity(vectorizer: TfidfVectorizer):\n",
        "  \"\"\"\n",
        "  Common function that will take different instantiations of `TfidfVectorizer`\n",
        "  \"\"\"\n",
        "\n",
        "  # this will do 2 things:\n",
        "  #   1. fit the TF-IDF vectorizer to the document corpus, and\n",
        "  #   2. transform the documents into TF-IDF vectors\n",
        "  document_vectors = vectorizer.fit_transform(documents)\n",
        "\n",
        "  # calculate word frequencies (TF-IDF values)\n",
        "  frequencies = document_vectors.toarray()\n",
        "\n",
        "  # get feature names to see which words are retained\n",
        "  terms = vectorizer.get_feature_names_out()\n",
        "\n",
        "  # print term frequencies for each document\n",
        "  print(\"Word Frequencies (TF-IDF values):\")\n",
        "  for i, doc in enumerate(documents):\n",
        "      print(f\"document #{i}: {doc[:30]}...\")\n",
        "      for j, term in enumerate(terms):\n",
        "          if frequencies[i, j] > 0:  # only show terms with non-zero TF-IDF\n",
        "              print(f\"  {term}: {frequencies[i, j]:.4f}\")\n",
        "      print()\n",
        "\n",
        "  # return `document_vectors` and vocabulary\n",
        "  return document_vectors, terms\n"
      ],
      "metadata": {
        "id": "GCIVAimuePPE",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# now invoke word_frequency_measure_similarity() with a simple `TfidfVectorizer`\n",
        "# without that any text pre-processing\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words=stop_words_list)\n",
        "\n",
        "document_vectors, vocabulary = word_frequency_measure_similarity(vectorizer);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fE2Sqd81fck",
        "outputId": "3d31dc8e-79c6-4c13-f858-ce76221d1d47"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Frequencies (TF-IDF values):\n",
            "document #0: Fresh Pomegranate from Anushka...\n",
            "  00kg: 0.1041\n",
            "  180gm: 0.1041\n",
            "  350: 0.1041\n",
            "  400gm: 0.1041\n",
            "  400gms: 0.1041\n",
            "  50: 0.0829\n",
            "  5kg: 0.1658\n",
            "  anushka: 0.0592\n",
            "  appearance: 0.1166\n",
            "  arils: 0.2083\n",
            "  avni: 0.0592\n",
            "  bhagwa: 0.2331\n",
            "  box: 0.1041\n",
            "  carton: 0.1770\n",
            "  cherry: 0.1166\n",
            "  color: 0.2331\n",
            "  count: 0.1041\n",
            "  dark: 0.2083\n",
            "  deep: 0.1166\n",
            "  delicious: 0.1166\n",
            "  details: 0.0885\n",
            "  enhances: 0.1166\n",
            "  extremely: 0.1166\n",
            "  fresh: 0.0741\n",
            "  fruit: 0.1658\n",
            "  india: 0.1041\n",
            "  international: 0.0592\n",
            "  kg: 0.0829\n",
            "  known: 0.1166\n",
            "  life: 0.0953\n",
            "  maximum: 0.1041\n",
            "  minimum: 0.1041\n",
            "  net: 0.2083\n",
            "  numbers: 0.1041\n",
            "  packaging: 0.0741\n",
            "  packed: 0.1041\n",
            "  per: 0.0741\n",
            "  pleasing: 0.1166\n",
            "  pomegranate: 0.2083\n",
            "  premium: 0.1166\n",
            "  promoting: 0.1166\n",
            "  red: 0.2963\n",
            "  rugged: 0.1166\n",
            "  seed: 0.1166\n",
            "  shelf: 0.1166\n",
            "  skin: 0.0885\n",
            "  soft: 0.1041\n",
            "  sweet: 0.0953\n",
            "  taste: 0.0885\n",
            "  variety: 0.1041\n",
            "  weight: 0.3124\n",
            "  whilst: 0.1166\n",
            "  widely: 0.1041\n",
            "  wt: 0.1041\n",
            "\n",
            "document #1: Fresh Pomegranate Arakta from ...\n",
            "  00kg: 0.0750\n",
            "  10: 0.0840\n",
            "  12: 0.0637\n",
            "  15: 0.0840\n",
            "  180gm: 0.0750\n",
            "  20: 0.0840\n",
            "  220: 0.0840\n",
            "  225: 0.0840\n",
            "  275: 0.0840\n",
            "  275gms: 0.0840\n",
            "  290: 0.0840\n",
            "  320gms: 0.0840\n",
            "  325gms: 0.0840\n",
            "  350: 0.0750\n",
            "  400gm: 0.0750\n",
            "  400gms: 0.0750\n",
            "  4400: 0.0840\n",
            "  50: 0.0597\n",
            "  5500: 0.0840\n",
            "  5kg: 0.1194\n",
            "  ability: 0.1126\n",
            "  also: 0.0597\n",
            "  anushka: 0.0426\n",
            "  april: 0.0687\n",
            "  arakta: 0.0840\n",
            "  arils: 0.0750\n",
            "  attractive: 0.0840\n",
            "  august: 0.0840\n",
            "  availability: 0.0637\n",
            "  avni: 0.0426\n",
            "  bigger: 0.0840\n",
            "  bold: 0.0840\n",
            "  box: 0.0750\n",
            "  carton: 0.3187\n",
            "  cartons: 0.1912\n",
            "  container: 0.1067\n",
            "  count: 0.0750\n",
            "  dark: 0.0750\n",
            "  dec: 0.0840\n",
            "  details: 0.0637\n",
            "  february: 0.0687\n",
            "  fresh: 0.0534\n",
            "  fruit: 0.0597\n",
            "  glossy: 0.0840\n",
            "  international: 0.0426\n",
            "  january: 0.0687\n",
            "  july: 0.0840\n",
            "  kg: 0.0597\n",
            "  load: 0.1126\n",
            "  loading: 0.0840\n",
            "  march: 0.0687\n",
            "  maximum: 0.0750\n",
            "  minimum: 0.0750\n",
            "  net: 0.1501\n",
            "  nov: 0.0840\n",
            "  numbers: 0.3001\n",
            "  october: 0.0840\n",
            "  packaging: 0.0534\n",
            "  packed: 0.3001\n",
            "  pallet: 0.0840\n",
            "  pallets: 0.1680\n",
            "  per: 0.3736\n",
            "  pomegranate: 0.1501\n",
            "  possess: 0.0840\n",
            "  read: 0.0687\n",
            "  red: 0.1067\n",
            "  seeds: 0.0840\n",
            "  september: 0.0840\n",
            "  size: 0.0637\n",
            "  skin: 0.0637\n",
            "  soft: 0.0750\n",
            "  sweet: 0.1373\n",
            "  taste: 0.0637\n",
            "  weight: 0.2251\n",
            "  wt: 0.0750\n",
            "\n",
            "document #2: About Us Anushka Avni Internat...\n",
            "  aai: 0.1562\n",
            "  agro: 0.1562\n",
            "  anushka: 0.1183\n",
            "  assortment: 0.1562\n",
            "  available: 0.1480\n",
            "  avni: 0.1183\n",
            "  best: 0.1905\n",
            "  buyers: 0.1562\n",
            "  come: 0.1408\n",
            "  exporter: 0.1562\n",
            "  feel: 0.1562\n",
            "  follow: 0.1768\n",
            "  huge: 0.1562\n",
            "  international: 0.1183\n",
            "  market: 0.1562\n",
            "  offer: 0.1562\n",
            "  one: 0.1285\n",
            "  pleasure: 0.1562\n",
            "  practices: 0.1905\n",
            "  presenting: 0.1562\n",
            "  products: 0.1562\n",
            "  proud: 0.1562\n",
            "  quality: 0.1480\n",
            "  read: 0.1905\n",
            "  recognizing: 0.1562\n",
            "  renowned: 0.1562\n",
            "  standard: 0.1562\n",
            "  suppliers: 0.1344\n",
            "  supplying: 0.1905\n",
            "  takes: 0.1562\n",
            "  us: 0.4687\n",
            "  wide: 0.1562\n",
            "  world: 0.1562\n",
            "\n",
            "document #3: About Us Anushka Avni Internat...\n",
            "  aai: 0.1562\n",
            "  agro: 0.1562\n",
            "  anushka: 0.1183\n",
            "  assortment: 0.1562\n",
            "  available: 0.1480\n",
            "  avni: 0.1183\n",
            "  best: 0.1905\n",
            "  buyers: 0.1562\n",
            "  come: 0.1408\n",
            "  exporter: 0.1562\n",
            "  feel: 0.1562\n",
            "  follow: 0.1768\n",
            "  huge: 0.1562\n",
            "  international: 0.1183\n",
            "  market: 0.1562\n",
            "  offer: 0.1562\n",
            "  one: 0.1285\n",
            "  pleasure: 0.1562\n",
            "  practices: 0.1905\n",
            "  presenting: 0.1562\n",
            "  products: 0.1562\n",
            "  proud: 0.1562\n",
            "  quality: 0.1480\n",
            "  read: 0.1905\n",
            "  recognizing: 0.1562\n",
            "  renowned: 0.1562\n",
            "  standard: 0.1562\n",
            "  suppliers: 0.1344\n",
            "  supplying: 0.1905\n",
            "  takes: 0.1562\n",
            "  us: 0.4687\n",
            "  wide: 0.1562\n",
            "  world: 0.1562\n",
            "\n",
            "document #4: White Onions from Anushka Avni...\n",
            "  10kg: 0.0931\n",
            "  12: 0.0864\n",
            "  15kg: 0.0931\n",
            "  17kg: 0.0931\n",
            "  18kg: 0.0931\n",
            "  20ft: 0.0931\n",
            "  20kg: 0.0931\n",
            "  25kg: 0.0931\n",
            "  28: 0.0931\n",
            "  30: 0.0931\n",
            "  30kg: 0.0931\n",
            "  3kg: 0.0931\n",
            "  40ft: 0.0931\n",
            "  45: 0.1862\n",
            "  50: 0.0810\n",
            "  55: 0.1862\n",
            "  5kg: 0.1619\n",
            "  60: 0.0931\n",
            "  70: 0.0931\n",
            "  9kg: 0.0931\n",
            "  ability: 0.0763\n",
            "  acclaimed: 0.1138\n",
            "  anushka: 0.0578\n",
            "  avni: 0.0578\n",
            "  bag: 0.1862\n",
            "  benefits: 0.1138\n",
            "  container: 0.1447\n",
            "  cuisines: 0.1138\n",
            "  different: 0.1138\n",
            "  exporters: 0.0931\n",
            "  fresh: 0.1447\n",
            "  health: 0.1017\n",
            "  international: 0.0578\n",
            "  jute: 0.0931\n",
            "  kinds: 0.0931\n",
            "  like: 0.0810\n",
            "  load: 0.0763\n",
            "  major: 0.0864\n",
            "  mesh: 0.0931\n",
            "  mm: 0.3724\n",
            "  mt: 0.1862\n",
            "  odo: 0.0931\n",
            "  onion: 0.0931\n",
            "  onions: 0.4321\n",
            "  packaging: 0.0723\n",
            "  per: 0.1447\n",
            "  pink: 0.1017\n",
            "  red: 0.1447\n",
            "  refer: 0.0931\n",
            "  sizes: 0.0931\n",
            "  suppliers: 0.0657\n",
            "  used: 0.0810\n",
            "  white: 0.2793\n",
            "  widely: 0.1017\n",
            "\n",
            "document #5: Anushka Avni International (AA...\n",
            "  aai: 0.1865\n",
            "  agro: 0.1865\n",
            "  anushka: 0.1412\n",
            "  assortment: 0.1865\n",
            "  available: 0.1767\n",
            "  avni: 0.1412\n",
            "  buyers: 0.1865\n",
            "  come: 0.1681\n",
            "  exporter: 0.1865\n",
            "  feel: 0.1865\n",
            "  huge: 0.1865\n",
            "  international: 0.1412\n",
            "  market: 0.1865\n",
            "  offer: 0.1865\n",
            "  one: 0.1535\n",
            "  pleasure: 0.1865\n",
            "  presenting: 0.1865\n",
            "  products: 0.1865\n",
            "  proud: 0.1865\n",
            "  quality: 0.1767\n",
            "  recognizing: 0.1865\n",
            "  renowned: 0.1865\n",
            "  standard: 0.1865\n",
            "  suppliers: 0.1604\n",
            "  takes: 0.1865\n",
            "  us: 0.3730\n",
            "  wide: 0.1865\n",
            "  world: 0.1865\n",
            "\n",
            "document #6: To a botanist, a fruit is an e...\n",
            "  apples: 0.2004\n",
            "  apricots: 0.2004\n",
            "  bean: 0.2004\n",
            "  botanist: 0.1790\n",
            "  corn: 0.2004\n",
            "  cucumbers: 0.2004\n",
            "  develops: 0.2004\n",
            "  eggplants: 0.2004\n",
            "  entity: 0.2004\n",
            "  fertilized: 0.2004\n",
            "  flower: 0.2004\n",
            "  fruit: 0.1425\n",
            "  fruits: 0.1790\n",
            "  kernels: 0.2004\n",
            "  mangos: 0.2004\n",
            "  means: 0.2004\n",
            "  melons: 0.2004\n",
            "  ovary: 0.2004\n",
            "  pea: 0.2004\n",
            "  peaches: 0.2004\n",
            "  pears: 0.2004\n",
            "  peppers: 0.2004\n",
            "  pods: 0.2004\n",
            "  pumpkins: 0.2004\n",
            "  squash: 0.2004\n",
            "  tomatoes: 0.1790\n",
            "\n",
            "document #7: Nutrition is the biochemical a...\n",
            "  absorption: 0.1679\n",
            "  also: 0.1194\n",
            "  assimilation: 0.1679\n",
            "  biochemical: 0.1679\n",
            "  biosynthesis: 0.1679\n",
            "  called: 0.1275\n",
            "  catabolism: 0.1679\n",
            "  excretion: 0.1679\n",
            "  includes: 0.1679\n",
            "  ingestion: 0.1679\n",
            "  intake: 0.1679\n",
            "  life: 0.1373\n",
            "  nutrition: 0.4120\n",
            "  nutritional: 0.1679\n",
            "  organism: 0.1373\n",
            "  physiological: 0.3359\n",
            "  process: 0.3359\n",
            "  science: 0.4120\n",
            "  studies: 0.1679\n",
            "  support: 0.1679\n",
            "  uses: 0.1679\n",
            "\n",
            "document #8: Nutrients are substances used ...\n",
            "  animals: 0.1219\n",
            "  carbohydrates: 0.2437\n",
            "  classes: 0.1219\n",
            "  dietary: 0.2437\n",
            "  either: 0.1219\n",
            "  fats: 0.2437\n",
            "  fiber: 0.2437\n",
            "  gram: 0.1219\n",
            "  grouped: 0.1219\n",
            "  grow: 0.1219\n",
            "  humans: 0.1089\n",
            "  including: 0.1089\n",
            "  macronutrients: 0.1219\n",
            "  major: 0.0925\n",
            "  microgram: 0.1219\n",
            "  micronutrients: 0.1219\n",
            "  milligram: 0.1219\n",
            "  minerals: 0.2437\n",
            "  needed: 0.2437\n",
            "  nutrients: 0.3656\n",
            "  organism: 0.0996\n",
            "  proteins: 0.2437\n",
            "  quantities: 0.2437\n",
            "  relevant: 0.1219\n",
            "  reproduce: 0.1219\n",
            "  seven: 0.1219\n",
            "  substances: 0.1219\n",
            "  survive: 0.1219\n",
            "  used: 0.0867\n",
            "  vitamins: 0.2437\n",
            "  water: 0.2437\n",
            "\n",
            "document #9: In nutrition, the diet of an o...\n",
            "  availability: 0.2299\n",
            "  determined: 0.3028\n",
            "  diet: 0.2705\n",
            "  eats: 0.3028\n",
            "  foods: 0.5411\n",
            "  largely: 0.3028\n",
            "  nutrition: 0.2476\n",
            "  organism: 0.2476\n",
            "  palatability: 0.3028\n",
            "  sum: 0.3028\n",
            "\n",
            "document #10: Canada's Food Guide is a nutri...\n",
            "  2007: 0.0895\n",
            "  also: 0.0636\n",
            "  basic: 0.0895\n",
            "  behaviours: 0.0895\n",
            "  behind: 0.0895\n",
            "  canada: 0.3397\n",
            "  canadian: 0.0800\n",
            "  choosing: 0.0895\n",
            "  come: 0.0541\n",
            "  day: 0.0800\n",
            "  designed: 0.0895\n",
            "  diet: 0.0800\n",
            "  eating: 0.0895\n",
            "  education: 0.0895\n",
            "  follow: 0.0679\n",
            "  food: 0.1599\n",
            "  foods: 0.3998\n",
            "  forms: 0.0895\n",
            "  fruits: 0.0800\n",
            "  government: 0.0895\n",
            "  grain: 0.0895\n",
            "  guide: 0.2685\n",
            "  guides: 0.0895\n",
            "  habits: 0.0895\n",
            "  health: 0.1599\n",
            "  healthy: 0.3580\n",
            "  help: 0.0895\n",
            "  highly: 0.0895\n",
            "  including: 0.0800\n",
            "  income: 0.0895\n",
            "  increase: 0.0895\n",
            "  lifestyles: 0.0895\n",
            "  limiting: 0.0895\n",
            "  number: 0.0895\n",
            "  nutrition: 0.0732\n",
            "  often: 0.0800\n",
            "  people: 0.1790\n",
            "  plants: 0.0800\n",
            "  plenty: 0.0895\n",
            "  processed: 0.0895\n",
            "  produced: 0.0895\n",
            "  promote: 0.0895\n",
            "  protein: 0.1790\n",
            "  publication: 0.0895\n",
            "  recommends: 0.2685\n",
            "  reported: 0.0895\n",
            "  requested: 0.0895\n",
            "  second: 0.0895\n",
            "  states: 0.0800\n",
            "  tax: 0.0895\n",
            "  tools: 0.0800\n",
            "  variety: 0.0800\n",
            "  vegetables: 0.0895\n",
            "  website: 0.0895\n",
            "  whole: 0.0895\n",
            "\n",
            "document #11: UK, Nether Land, Russia, Canad...\n",
            "  arabia: 0.2346\n",
            "  bahrain: 0.2346\n",
            "  bangladesh: 0.2346\n",
            "  canada: 0.1781\n",
            "  hongkong: 0.2346\n",
            "  land: 0.2346\n",
            "  lanka: 0.2346\n",
            "  malaysia: 0.2096\n",
            "  maldives: 0.2346\n",
            "  mauritius: 0.2346\n",
            "  nether: 0.2346\n",
            "  oman: 0.2346\n",
            "  qatar: 0.2346\n",
            "  russia: 0.2346\n",
            "  saudi: 0.2346\n",
            "  singapore: 0.2096\n",
            "  sri: 0.2346\n",
            "  uae: 0.2346\n",
            "  uk: 0.2346\n",
            "\n",
            "document #12: Canadian Industry Statistics (...\n",
            "  analyses: 0.2866\n",
            "  canada: 0.2176\n",
            "  canadian: 0.2561\n",
            "  cis: 0.2866\n",
            "  data: 0.2561\n",
            "  economic: 0.2866\n",
            "  indicators: 0.2866\n",
            "  industry: 0.5732\n",
            "  many: 0.2866\n",
            "  statistics: 0.2866\n",
            "\n",
            "document #13: Red Onions from Anushka Avni I...\n",
            "  10kg: 0.0853\n",
            "  12: 0.0792\n",
            "  15kg: 0.0853\n",
            "  17kg: 0.0853\n",
            "  18kg: 0.0853\n",
            "  20ft: 0.0853\n",
            "  20kg: 0.0853\n",
            "  25kg: 0.0853\n",
            "  28: 0.0853\n",
            "  30: 0.0853\n",
            "  30kg: 0.0853\n",
            "  3kg: 0.0853\n",
            "  40ft: 0.0853\n",
            "  45: 0.1706\n",
            "  50: 0.0742\n",
            "  55: 0.1706\n",
            "  5kg: 0.1484\n",
            "  60: 0.0853\n",
            "  70: 0.0853\n",
            "  9kg: 0.0853\n",
            "  ability: 0.0700\n",
            "  anushka: 0.0530\n",
            "  avni: 0.0530\n",
            "  bag: 0.1706\n",
            "  called: 0.0792\n",
            "  container: 0.1326\n",
            "  cultivars: 0.0932\n",
            "  exporters: 0.0853\n",
            "  flesh: 0.0932\n",
            "  fresh: 0.0663\n",
            "  indian: 0.0932\n",
            "  international: 0.0530\n",
            "  jute: 0.0853\n",
            "  kinds: 0.0853\n",
            "  like: 0.0742\n",
            "  load: 0.0700\n",
            "  major: 0.0792\n",
            "  mesh: 0.0853\n",
            "  mm: 0.3412\n",
            "  mt: 0.1706\n",
            "  odo: 0.0853\n",
            "  onion: 0.0853\n",
            "  onions: 0.4751\n",
            "  packaging: 0.0663\n",
            "  per: 0.1326\n",
            "  purple: 0.0932\n",
            "  purplish: 0.1043\n",
            "  red: 0.3977\n",
            "  refer: 0.0853\n",
            "  sizes: 0.0853\n",
            "  skin: 0.0792\n",
            "  sometimes: 0.0932\n",
            "  suppliers: 0.0602\n",
            "  tinged: 0.0932\n",
            "  white: 0.1706\n",
            "\n",
            "document #14: Berry Size: 18mm and above Pac...\n",
            "  18mm: 0.1290\n",
            "  2040: 0.1290\n",
            "  2400: 0.1290\n",
            "  3400: 0.1290\n",
            "  500: 0.1290\n",
            "  ability: 0.0968\n",
            "  april: 0.1181\n",
            "  availability: 0.1096\n",
            "  bags: 0.2580\n",
            "  berry: 0.1181\n",
            "  carry: 0.2580\n",
            "  carton: 0.1096\n",
            "  cartons: 0.3288\n",
            "  container: 0.2753\n",
            "  december: 0.1290\n",
            "  february: 0.1181\n",
            "  gms: 0.1290\n",
            "  january: 0.1181\n",
            "  kg: 0.4108\n",
            "  kilo: 0.2580\n",
            "  load: 0.0968\n",
            "  loose: 0.2362\n",
            "  march: 0.1181\n",
            "  packaging: 0.0918\n",
            "  packing: 0.1181\n",
            "  per: 0.2753\n",
            "  punnets10: 0.1290\n",
            "  size: 0.2192\n",
            "\n",
            "document #15: Pink Onions from Anushka Avni ...\n",
            "  10kg: 0.0816\n",
            "  12: 0.0757\n",
            "  15kg: 0.0816\n",
            "  17kg: 0.0816\n",
            "  18kg: 0.0816\n",
            "  20ft: 0.0816\n",
            "  20kg: 0.0816\n",
            "  25kg: 0.0816\n",
            "  28: 0.0816\n",
            "  30: 0.0816\n",
            "  30kg: 0.0816\n",
            "  3kg: 0.0816\n",
            "  40ft: 0.0816\n",
            "  45: 0.1632\n",
            "  50: 0.0709\n",
            "  55: 0.1632\n",
            "  5kg: 0.1419\n",
            "  60: 0.0816\n",
            "  70: 0.0816\n",
            "  9kg: 0.0816\n",
            "  ability: 0.0669\n",
            "  anushka: 0.0507\n",
            "  avni: 0.0507\n",
            "  bag: 0.1632\n",
            "  called: 0.0757\n",
            "  container: 0.1268\n",
            "  cultivars: 0.0891\n",
            "  exporters: 0.0816\n",
            "  flesh: 0.0891\n",
            "  fresh: 0.0634\n",
            "  indian: 0.0891\n",
            "  international: 0.0507\n",
            "  jute: 0.0816\n",
            "  kinds: 0.0816\n",
            "  like: 0.0709\n",
            "  load: 0.0669\n",
            "  major: 0.0757\n",
            "  mesh: 0.0816\n",
            "  mm: 0.3263\n",
            "  mt: 0.1632\n",
            "  odo: 0.0816\n",
            "  onion: 0.0816\n",
            "  onions: 0.5301\n",
            "  packaging: 0.0634\n",
            "  per: 0.1268\n",
            "  pink: 0.3565\n",
            "  red: 0.1902\n",
            "  refer: 0.0816\n",
            "  sizes: 0.0816\n",
            "  skin: 0.0757\n",
            "  sometimes: 0.0891\n",
            "  summer: 0.0998\n",
            "  suppliers: 0.0575\n",
            "  tinged: 0.0891\n",
            "  white: 0.1632\n",
            "\n",
            "document #16: Anushka Avni International (AA...\n",
            "  aai: 0.0830\n",
            "  across: 0.1237\n",
            "  agro: 0.0830\n",
            "  anushka: 0.0628\n",
            "  assortment: 0.0830\n",
            "  available: 0.0786\n",
            "  avni: 0.0628\n",
            "  aware: 0.1237\n",
            "  background: 0.1237\n",
            "  best: 0.3035\n",
            "  buyers: 0.0830\n",
            "  client: 0.1237\n",
            "  come: 0.0748\n",
            "  company: 0.2211\n",
            "  consider: 0.1237\n",
            "  deliver: 0.1237\n",
            "  demand: 0.1237\n",
            "  demands: 0.1237\n",
            "  destination: 0.1237\n",
            "  domestic: 0.1237\n",
            "  established: 0.1237\n",
            "  evolving: 0.1237\n",
            "  exporter: 0.0830\n",
            "  exportingagro: 0.1237\n",
            "  fact: 0.1237\n",
            "  feel: 0.0830\n",
            "  final: 0.1237\n",
            "  follow: 0.0939\n",
            "  forproviding: 0.1237\n",
            "  handling: 0.1237\n",
            "  harvest: 0.1237\n",
            "  horticultureand: 0.1237\n",
            "  huge: 0.0830\n",
            "  initiatives: 0.1237\n",
            "  international: 0.0628\n",
            "  internationalmarket: 0.1237\n",
            "  keep: 0.1237\n",
            "  market: 0.1659\n",
            "  moreover: 0.1237\n",
            "  offer: 0.0830\n",
            "  ofthe: 0.1237\n",
            "  one: 0.0683\n",
            "  perishables: 0.1237\n",
            "  pleasure: 0.0830\n",
            "  practices: 0.1012\n",
            "  presenting: 0.0830\n",
            "  products: 0.1659\n",
            "  professionals: 0.1237\n",
            "  proud: 0.0830\n",
            "  quality: 0.2359\n",
            "  recognizing: 0.0830\n",
            "  renowned: 0.0830\n",
            "  requirement: 0.1237\n",
            "  standard: 0.0830\n",
            "  strong: 0.1237\n",
            "  suppliers: 0.0714\n",
            "  supplying: 0.1012\n",
            "  takes: 0.1659\n",
            "  thecustomers: 0.2474\n",
            "  thoroughly: 0.1237\n",
            "  till: 0.1237\n",
            "  us: 0.1659\n",
            "  wide: 0.0830\n",
            "  world: 0.0830\n",
            "\n",
            "document #17: We are one of the leading orga...\n",
            "  bulk: 0.2272\n",
            "  clients: 0.2544\n",
            "  customers: 0.2544\n",
            "  delivering: 0.2544\n",
            "  details: 0.1931\n",
            "  engaged: 0.2544\n",
            "  fresh: 0.1616\n",
            "  leading: 0.2544\n",
            "  malaysia: 0.2272\n",
            "  manufacture: 0.2544\n",
            "  one: 0.1403\n",
            "  onions: 0.1931\n",
            "  organizations: 0.2544\n",
            "  philippines: 0.2544\n",
            "  product: 0.2272\n",
            "  quality: 0.1616\n",
            "  requirements: 0.2544\n",
            "  singapore: 0.2272\n",
            "  vietnam: 0.2544\n",
            "\n",
            "document #18: Fresh Tomatoes from Anushka Av...\n",
            "  00: 0.2029\n",
            "  actively: 0.2029\n",
            "  anushka: 0.1030\n",
            "  avni: 0.1030\n",
            "  cartons: 0.1540\n",
            "  chutney: 0.2029\n",
            "  details: 0.1540\n",
            "  emerged: 0.2029\n",
            "  enhancer: 0.2029\n",
            "  exporting: 0.2029\n",
            "  free: 0.2029\n",
            "  fresh: 0.1289\n",
            "  international: 0.1030\n",
            "  kg: 0.2885\n",
            "  one: 0.1119\n",
            "  organization: 0.2029\n",
            "  packing: 0.1659\n",
            "  participating: 0.2029\n",
            "  preservatives: 0.2029\n",
            "  product: 0.1812\n",
            "  pure: 0.2029\n",
            "  red: 0.1289\n",
            "  reputed: 0.2029\n",
            "  suppling: 0.2029\n",
            "  taste: 0.1540\n",
            "  tomatoes: 0.3625\n",
            "  useful: 0.2029\n",
            "\n",
            "document #19: Anushka Avni International (AA...\n",
            "  aai: 0.1865\n",
            "  agro: 0.1865\n",
            "  anushka: 0.1412\n",
            "  assortment: 0.1865\n",
            "  available: 0.1767\n",
            "  avni: 0.1412\n",
            "  buyers: 0.1865\n",
            "  come: 0.1681\n",
            "  exporter: 0.1865\n",
            "  feel: 0.1865\n",
            "  huge: 0.1865\n",
            "  international: 0.1412\n",
            "  market: 0.1865\n",
            "  offer: 0.1865\n",
            "  one: 0.1535\n",
            "  pleasure: 0.1865\n",
            "  presenting: 0.1865\n",
            "  products: 0.1865\n",
            "  proud: 0.1865\n",
            "  quality: 0.1767\n",
            "  recognizing: 0.1865\n",
            "  renowned: 0.1865\n",
            "  standard: 0.1865\n",
            "  suppliers: 0.1604\n",
            "  takes: 0.1865\n",
            "  us: 0.3730\n",
            "  wide: 0.1865\n",
            "  world: 0.1865\n",
            "\n",
            "document #20: Welcome to Anushka Avni Intern...\n",
            "  aai: 0.3197\n",
            "  agro: 0.1599\n",
            "  anushka: 0.2421\n",
            "  assortment: 0.1599\n",
            "  available: 0.1515\n",
            "  avni: 0.2421\n",
            "  buyers: 0.1599\n",
            "  come: 0.1441\n",
            "  exporter: 0.1599\n",
            "  feel: 0.1599\n",
            "  huge: 0.1599\n",
            "  international: 0.2421\n",
            "  market: 0.1599\n",
            "  offer: 0.1599\n",
            "  one: 0.1315\n",
            "  pleasure: 0.1599\n",
            "  presenting: 0.1599\n",
            "  products: 0.1599\n",
            "  proud: 0.1599\n",
            "  quality: 0.1515\n",
            "  recognizing: 0.1599\n",
            "  renowned: 0.1599\n",
            "  standard: 0.1599\n",
            "  suppliers: 0.1375\n",
            "  takes: 0.1599\n",
            "  us: 0.3197\n",
            "  welcome: 0.2384\n",
            "  wide: 0.1599\n",
            "  world: 0.1599\n",
            "\n",
            "document #21: Thomson Seedless These grapes ...\n",
            "  16mm: 0.2172\n",
            "  account: 0.2172\n",
            "  berry: 0.1776\n",
            "  bulk: 0.1940\n",
            "  crunchy: 0.2172\n",
            "  exports: 0.2172\n",
            "  grape: 0.2172\n",
            "  grapes: 0.1776\n",
            "  india: 0.1940\n",
            "  seedless: 0.5329\n",
            "  size: 0.1649\n",
            "  sweet: 0.1776\n",
            "  table: 0.2172\n",
            "  tart: 0.2172\n",
            "  thomson: 0.4344\n",
            "\n",
            "document #22: Black Sharad Seedless Grapes C...\n",
            "  18mm: 0.1094\n",
            "  2040: 0.1094\n",
            "  2400: 0.1094\n",
            "  3400: 0.1094\n",
            "  500: 0.1094\n",
            "  ability: 0.0821\n",
            "  april: 0.1001\n",
            "  availability: 0.0930\n",
            "  bags: 0.2188\n",
            "  berry: 0.2003\n",
            "  black: 0.2188\n",
            "  carry: 0.2188\n",
            "  carton: 0.0930\n",
            "  cartons: 0.2789\n",
            "  container: 0.2335\n",
            "  crisp: 0.1225\n",
            "  december: 0.1094\n",
            "  february: 0.1001\n",
            "  gms: 0.1094\n",
            "  grapes: 0.2003\n",
            "  january: 0.1001\n",
            "  kg: 0.3484\n",
            "  kilo: 0.2188\n",
            "  load: 0.0821\n",
            "  loose: 0.2003\n",
            "  march: 0.1001\n",
            "  medium: 0.1225\n",
            "  oval: 0.1225\n",
            "  packaging: 0.0778\n",
            "  packing: 0.1001\n",
            "  per: 0.2335\n",
            "  punnets10: 0.1094\n",
            "  purple: 0.1094\n",
            "  seedless: 0.1001\n",
            "  shades: 0.1225\n",
            "  shaped: 0.1094\n",
            "  sharad: 0.1225\n",
            "  size: 0.1859\n",
            "  sized: 0.1225\n",
            "  taste: 0.0930\n",
            "  usually: 0.1225\n",
            "  vary: 0.1225\n",
            "\n",
            "document #23: Flame / Red seedless grapesFla...\n",
            "  along: 0.3767\n",
            "  flame: 0.3767\n",
            "  grapes: 0.3081\n",
            "  grapesflame: 0.3767\n",
            "  one: 0.2079\n",
            "  popular: 0.3767\n",
            "  red: 0.2394\n",
            "  seedless: 0.3081\n",
            "  varieties: 0.3767\n",
            "\n",
            "document #24: A Dictionary in Python is an u...\n",
            "  collection: 0.1736\n",
            "  data: 0.4652\n",
            "  dictionary: 0.3471\n",
            "  element: 0.1736\n",
            "  hold: 0.1736\n",
            "  holds: 0.1736\n",
            "  key: 0.1736\n",
            "  like: 0.1234\n",
            "  map: 0.1736\n",
            "  pair: 0.1736\n",
            "  python: 0.1736\n",
            "  single: 0.1736\n",
            "  store: 0.1736\n",
            "  types: 0.1736\n",
            "  unlike: 0.1736\n",
            "  unordered: 0.1736\n",
            "  used: 0.1234\n",
            "  value: 0.3471\n",
            "  values: 0.3471\n",
            "\n",
            "document #25: Botany originated in prehistor...\n",
            "  1540s: 0.1107\n",
            "  1753: 0.1107\n",
            "  academic: 0.1107\n",
            "  attached: 0.2213\n",
            "  beginnings: 0.1107\n",
            "  binomial: 0.1107\n",
            "  biological: 0.1107\n",
            "  botanical: 0.2213\n",
            "  botany: 0.0989\n",
            "  branches: 0.1107\n",
            "  carl: 0.1107\n",
            "  catalogue: 0.1107\n",
            "  collections: 0.1107\n",
            "  contained: 0.1107\n",
            "  cultivate: 0.1107\n",
            "  day: 0.0989\n",
            "  describe: 0.1107\n",
            "  earliest: 0.1107\n",
            "  early: 0.1107\n",
            "  edible: 0.1107\n",
            "  efforts: 0.2213\n",
            "  facilitated: 0.1107\n",
            "  first: 0.0989\n",
            "  forerunners: 0.1107\n",
            "  founded: 0.1107\n",
            "  garden: 0.1107\n",
            "  gardens: 0.3320\n",
            "  herbalism: 0.1107\n",
            "  humans: 0.0989\n",
            "  identify: 0.1107\n",
            "  importance: 0.1107\n",
            "  later: 0.1107\n",
            "  led: 0.1107\n",
            "  linnaeus: 0.1107\n",
            "  making: 0.1107\n",
            "  medical: 0.1107\n",
            "  medicinal: 0.1107\n",
            "  medieval: 0.1107\n",
            "  monasteries: 0.1107\n",
            "  naming: 0.1107\n",
            "  nomenclature: 0.1107\n",
            "  often: 0.0989\n",
            "  oldest: 0.1107\n",
            "  one: 0.1221\n",
            "  onwards: 0.1107\n",
            "  originated: 0.1107\n",
            "  padua: 0.1107\n",
            "  physic: 0.1107\n",
            "  plant: 0.0989\n",
            "  plants: 0.2966\n",
            "  poisonous: 0.1107\n",
            "  prehistory: 0.1107\n",
            "  remains: 0.1107\n",
            "  science: 0.0905\n",
            "  species: 0.1107\n",
            "  study: 0.1107\n",
            "  system: 0.1107\n",
            "  taxonomy: 0.1107\n",
            "  universities: 0.1107\n",
            "  use: 0.0989\n",
            "\n",
            "document #26: Semantic similarity is a metri...\n",
            "  according: 0.1439\n",
            "  based: 0.1439\n",
            "  comparison: 0.1439\n",
            "  concepts: 0.1439\n",
            "  content: 0.1439\n",
            "  defined: 0.1439\n",
            "  describing: 0.1439\n",
            "  description: 0.1439\n",
            "  distance: 0.1439\n",
            "  documents: 0.1439\n",
            "  estimate: 0.1439\n",
            "  idea: 0.1439\n",
            "  information: 0.1439\n",
            "  instances: 0.1439\n",
            "  items: 0.1439\n",
            "  language: 0.1439\n",
            "  lexicographical: 0.1439\n",
            "  likeness: 0.1439\n",
            "  mathematical: 0.1439\n",
            "  meaning: 0.2878\n",
            "  metric: 0.1439\n",
            "  nature: 0.1439\n",
            "  numerical: 0.1439\n",
            "  obtained: 0.1439\n",
            "  opposed: 0.1439\n",
            "  relationship: 0.1439\n",
            "  semantic: 0.4316\n",
            "  set: 0.1439\n",
            "  similarity: 0.2878\n",
            "  strength: 0.1439\n",
            "  supporting: 0.1439\n",
            "  terms: 0.1439\n",
            "  tools: 0.1285\n",
            "  units: 0.1439\n",
            "  used: 0.1023\n",
            "\n",
            "document #27: Botany, also called plant scie...\n",
            "  also: 0.1261\n",
            "  biology: 0.3547\n",
            "  botanist: 0.1584\n",
            "  botany: 0.1584\n",
            "  branch: 0.1774\n",
            "  called: 0.1346\n",
            "  field: 0.1774\n",
            "  life: 0.1450\n",
            "  phytologist: 0.1774\n",
            "  phytology: 0.1774\n",
            "  plant: 0.6338\n",
            "  science: 0.2901\n",
            "  scientist: 0.3547\n",
            "  specialises: 0.1774\n",
            "\n",
            "document #28: The Ford Bronco is a model lin...\n",
            "  1966: 0.1011\n",
            "  1996: 0.1011\n",
            "  2021: 0.2022\n",
            "  available: 0.0642\n",
            "  badlands: 0.1011\n",
            "  banks: 0.1011\n",
            "  base: 0.1011\n",
            "  beginning: 0.1011\n",
            "  bend: 0.1011\n",
            "  big: 0.1011\n",
            "  black: 0.0903\n",
            "  bronco: 0.4043\n",
            "  canada: 0.1535\n",
            "  come: 0.0611\n",
            "  company: 0.0903\n",
            "  deliveries: 0.1011\n",
            "  developed: 0.1011\n",
            "  diamond: 0.1011\n",
            "  first: 0.1806\n",
            "  five: 0.1011\n",
            "  ford: 0.3033\n",
            "  generation: 0.1011\n",
            "  generations: 0.1011\n",
            "  line: 0.2022\n",
            "  manufactured: 0.1011\n",
            "  marketed: 0.1011\n",
            "  model: 0.5054\n",
            "  outer: 0.1011\n",
            "  six: 0.1011\n",
            "  sixth: 0.1011\n",
            "  sold: 0.2022\n",
            "  sport: 0.1011\n",
            "  spring: 0.1011\n",
            "  suv: 0.1011\n",
            "  utility: 0.1011\n",
            "  vehicles: 0.1011\n",
            "  versions: 0.1011\n",
            "  wildtrak: 0.1011\n",
            "  year: 0.1011\n",
            "  years: 0.1011\n",
            "\n",
            "document #29: Fruit dishes are those that us...\n",
            "  also: 0.1638\n",
            "  condiments: 0.2303\n",
            "  dishes: 0.2303\n",
            "  fruit: 0.4913\n",
            "  included: 0.2303\n",
            "  ingredient: 0.4606\n",
            "  list: 0.2303\n",
            "  prepared: 0.2303\n",
            "  primary: 0.4606\n",
            "  use: 0.2057\n",
            "\n",
            "document #30: Neuro linguistic programming (...\n",
            "  1970s: 0.2306\n",
            "  approach: 0.2306\n",
            "  bandler: 0.2306\n",
            "  california: 0.2306\n",
            "  communication: 0.2306\n",
            "  created: 0.2306\n",
            "  development: 0.2306\n",
            "  grinder: 0.2306\n",
            "  john: 0.2306\n",
            "  linguistic: 0.2306\n",
            "  neuro: 0.2306\n",
            "  nlp: 0.2306\n",
            "  personal: 0.2306\n",
            "  programming: 0.2306\n",
            "  pseudoscientific: 0.2306\n",
            "  psychotherapy: 0.2306\n",
            "  richard: 0.2306\n",
            "  states: 0.2061\n",
            "  united: 0.2306\n",
            "\n",
            "document #31: A fruit serving bowl is a roun...\n",
            "  bottom: 0.1532\n",
            "  bowl: 0.4597\n",
            "  bowls: 0.1532\n",
            "  cap: 0.1532\n",
            "  center: 0.1532\n",
            "  characteristically: 0.1532\n",
            "  concentrated: 0.1532\n",
            "  container: 0.0974\n",
            "  contents: 0.1532\n",
            "  curve: 0.1532\n",
            "  dish: 0.1532\n",
            "  edges: 0.1532\n",
            "  especially: 0.1532\n",
            "  food: 0.2738\n",
            "  force: 0.1532\n",
            "  forming: 0.1532\n",
            "  fruit: 0.1090\n",
            "  gravity: 0.1532\n",
            "  holding: 0.1532\n",
            "  interior: 0.1532\n",
            "  like: 0.1090\n",
            "  liquids: 0.1532\n",
            "  loose: 0.1253\n",
            "  makes: 0.1532\n",
            "  naturally: 0.1532\n",
            "  prepare: 0.1532\n",
            "  round: 0.1532\n",
            "  seamless: 0.1532\n",
            "  serve: 0.1532\n",
            "  serving: 0.1532\n",
            "  shaped: 0.1369\n",
            "  spherical: 0.1532\n",
            "  suited: 0.1532\n",
            "  typically: 0.1532\n",
            "  used: 0.1090\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for each query, output the similarity scores for the top 5 documents with\n",
        "# th highest score, and interpret your results\n"
      ],
      "metadata": {
        "id": "6xTxqkDZeO4y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def top_N_documents_similarity_scores(fit_vectorizer: TfidfVectorizer, document_vectors, queries: list[str], n: int):\n",
        "  \"\"\"\n",
        "  Common function that will take different initializzations of `TfidfVectorizer`\n",
        "\n",
        "  :param fit_vectorizer: a TfidfVectorizer, already fit to a document corpus\n",
        "  :param document_vectors: the transformed documents vectors\n",
        "  \"\"\"\n",
        "\n",
        "  for query in queries:\n",
        "    # the vectorizer is already fit, just transform each query into a TF-IDF vector\n",
        "    # based on the same vocabulary and weights learned from the documents\n",
        "    query_vector = fit_vectorizer.transform([query])\n",
        "\n",
        "    # use cosine similarity between the query vector and all document vectors\n",
        "    cosine_similarities = linear_kernel(query_vector, document_vectors).flatten()\n",
        "\n",
        "    # sort the indices of the documents by their similarity scores in descending order\n",
        "    top_indices = cosine_similarities.argsort()[::-1]\n",
        "\n",
        "    print(f\"query: {query}\")\n",
        "    for index in top_indices[:5]:\n",
        "        print(f\">> score: {cosine_similarities[index]:.4f} for document #{index}: {documents[index][:30]}...\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "-yYunbgW2N7z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = ['fruits', 'vegetables', 'healthy foods in Canada']\n",
        "\n",
        "# now pass simple `vectorizer` and `document_vectors` already computed above\n",
        "# along with the query terms\n",
        "\n",
        "top_N_documents_similarity_scores(vectorizer, document_vectors, queries, 5);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l07L2Frk2Q3S",
        "outputId": "b2a3c3dd-94b5-4f52-d02d-e9a7b50a3374"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query: fruits\n",
            ">> score: 0.1790 for document #6: To a botanist, a fruit is an e...\n",
            ">> score: 0.0800 for document #10: Canada's Food Guide is a nutri...\n",
            ">> score: 0.0000 for document #31: A fruit serving bowl is a roun...\n",
            ">> score: 0.0000 for document #30: Neuro linguistic programming (...\n",
            ">> score: 0.0000 for document #1: Fresh Pomegranate Arakta from ...\n",
            "\n",
            "query: vegetables\n",
            ">> score: 0.0895 for document #10: Canada's Food Guide is a nutri...\n",
            ">> score: 0.0000 for document #31: A fruit serving bowl is a roun...\n",
            ">> score: 0.0000 for document #30: Neuro linguistic programming (...\n",
            ">> score: 0.0000 for document #1: Fresh Pomegranate Arakta from ...\n",
            ">> score: 0.0000 for document #2: About Us Anushka Avni Internat...\n",
            "\n",
            "query: healthy foods in Canada\n",
            ">> score: 0.6315 for document #10: Canada's Food Guide is a nutri...\n",
            ">> score: 0.3137 for document #9: In nutrition, the diet of an o...\n",
            ">> score: 0.1072 for document #12: Canadian Industry Statistics (...\n",
            ">> score: 0.0877 for document #11: UK, Nether Land, Russia, Canad...\n",
            ">> score: 0.0756 for document #28: The Ford Bronco is a model lin...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqrN27J9mZwb"
      },
      "source": [
        "## Repeat the same task after some preprocessing\n",
        "\n",
        "Use a minimum of 2 different text cleaning/standardization techniques (e.g. lemmatization, removing punctuation, etc)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSsdfQb9g46z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "843ebac7-e5c9-4b04-c40b-d93523adffdd"
      },
      "source": [
        "# e.g. you can use a lemmatizer to reduce words down to their\n",
        "# simplest 'lemma' (helpful when dealing with plurals)\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def lemmatized_preprocessor(text):\n",
        "  \"\"\"\n",
        "  Custom tokenizer preprocessor function for lemmatization\n",
        "  \"\"\"\n",
        "\n",
        "  # initialize the lemmatizer\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  # tokenize text\n",
        "  tokens = nltk.word_tokenize(text.lower())\n",
        "  # lemmatize each token\n",
        "  lemmatized_tokens = [\n",
        "      lemmatizer.lemmatize(token) for token in tokens if token.isalnum() and token not in stop_words\n",
        "  ]\n",
        "  return \" \".join(lemmatized_tokens)\n"
      ],
      "metadata": {
        "id": "b7nPQz04hCBb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# initialize the vectorizer with the custom `lemmatized_preprocessor`\n",
        "lemmatized_vectorizer = TfidfVectorizer(\n",
        "    stop_words=stop_words_list,\n",
        "    preprocessor=lemmatized_preprocessor)\n",
        "\n",
        "# invoke word_frequency_measure_similarity() with `lemmatized_vectorizer`\n",
        "lemmatized_document_vectors, lemmatized_vocabulary = word_frequency_measure_similarity(lemmatized_vectorizer);\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rt6gXS6i725A",
        "outputId": "314c537a-a992-4225-f6c1-c97e4e6880b8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['could', 'might', 'must', 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Frequencies (TF-IDF values):\n",
            "document #0: Fresh Pomegranate from Anushka...\n",
            "  180gm: 0.1085\n",
            "  400gm: 0.1085\n",
            "  anushka: 0.0617\n",
            "  appearance: 0.1214\n",
            "  aril: 0.2169\n",
            "  avni: 0.0617\n",
            "  bhagwa: 0.2428\n",
            "  box: 0.1085\n",
            "  carton: 0.1727\n",
            "  cherry: 0.1214\n",
            "  color: 0.2428\n",
            "  count: 0.1085\n",
            "  dark: 0.2169\n",
            "  deep: 0.1214\n",
            "  delicious: 0.1214\n",
            "  detail: 0.0922\n",
            "  enhances: 0.1214\n",
            "  extremely: 0.1214\n",
            "  fresh: 0.0772\n",
            "  fruit: 0.1628\n",
            "  india: 0.1085\n",
            "  international: 0.0617\n",
            "  kg: 0.0863\n",
            "  known: 0.1214\n",
            "  life: 0.0993\n",
            "  maximum: 0.1085\n",
            "  minimum: 0.1085\n",
            "  net: 0.2169\n",
            "  number: 0.0993\n",
            "  packaging: 0.0772\n",
            "  packed: 0.1085\n",
            "  per: 0.0772\n",
            "  pleasing: 0.1214\n",
            "  pomegranate: 0.2169\n",
            "  premium: 0.1214\n",
            "  promoting: 0.1214\n",
            "  red: 0.3086\n",
            "  rugged: 0.1214\n",
            "  seed: 0.1085\n",
            "  shelf: 0.1214\n",
            "  skin: 0.0922\n",
            "  soft: 0.1085\n",
            "  sweet: 0.1085\n",
            "  taste: 0.0922\n",
            "  variety: 0.0993\n",
            "  weight: 0.3254\n",
            "  whilst: 0.1214\n",
            "  widely: 0.1085\n",
            "  wt: 0.1085\n",
            "\n",
            "document #1: Fresh Pomegranate Arakta from ...\n",
            "  10: 0.0827\n",
            "  12: 0.0827\n",
            "  15: 0.0827\n",
            "  180gm: 0.0739\n",
            "  20: 0.0827\n",
            "  220: 0.0827\n",
            "  400gm: 0.0739\n",
            "  4400: 0.0827\n",
            "  5500: 0.0827\n",
            "  ability: 0.1110\n",
            "  also: 0.0588\n",
            "  anushka: 0.0420\n",
            "  april: 0.0677\n",
            "  arakta: 0.0827\n",
            "  aril: 0.0739\n",
            "  attractive: 0.0827\n",
            "  august: 0.0827\n",
            "  availability: 0.0628\n",
            "  avni: 0.0420\n",
            "  bigger: 0.0827\n",
            "  bold: 0.0827\n",
            "  box: 0.0739\n",
            "  carton: 0.4707\n",
            "  container: 0.1052\n",
            "  count: 0.0739\n",
            "  dark: 0.0739\n",
            "  dec: 0.0827\n",
            "  detail: 0.0628\n",
            "  february: 0.0677\n",
            "  fresh: 0.0526\n",
            "  fruit: 0.0555\n",
            "  glossy: 0.0827\n",
            "  international: 0.0420\n",
            "  january: 0.0677\n",
            "  july: 0.0827\n",
            "  kg: 0.0588\n",
            "  load: 0.1110\n",
            "  loading: 0.0827\n",
            "  march: 0.0677\n",
            "  maximum: 0.0739\n",
            "  minimum: 0.0739\n",
            "  net: 0.1478\n",
            "  nov: 0.0827\n",
            "  number: 0.2706\n",
            "  october: 0.0827\n",
            "  packaging: 0.0526\n",
            "  packed: 0.2957\n",
            "  pallet: 0.2482\n",
            "  per: 0.3681\n",
            "  pomegranate: 0.1478\n",
            "  possess: 0.0827\n",
            "  read: 0.0677\n",
            "  red: 0.1052\n",
            "  seed: 0.0739\n",
            "  september: 0.0827\n",
            "  size: 0.0526\n",
            "  skin: 0.0628\n",
            "  soft: 0.0739\n",
            "  sweet: 0.1478\n",
            "  taste: 0.0628\n",
            "  weight: 0.2217\n",
            "  wt: 0.0739\n",
            "\n",
            "document #2: About Us Anushka Avni Internat...\n",
            "  aai: 0.1825\n",
            "  agro: 0.1825\n",
            "  anushka: 0.1382\n",
            "  assortment: 0.1825\n",
            "  available: 0.1729\n",
            "  avni: 0.1382\n",
            "  best: 0.2225\n",
            "  buyer: 0.1825\n",
            "  come: 0.1645\n",
            "  exporter: 0.1569\n",
            "  feel: 0.1825\n",
            "  follow: 0.2065\n",
            "  huge: 0.1825\n",
            "  international: 0.1382\n",
            "  market: 0.1825\n",
            "  offer: 0.1825\n",
            "  one: 0.1501\n",
            "  pleasure: 0.1825\n",
            "  practice: 0.2225\n",
            "  presenting: 0.1825\n",
            "  product: 0.1645\n",
            "  proud: 0.1825\n",
            "  quality: 0.1729\n",
            "  read: 0.2225\n",
            "  recognizing: 0.1825\n",
            "  renowned: 0.1825\n",
            "  standard: 0.1825\n",
            "  supplier: 0.1569\n",
            "  take: 0.1825\n",
            "  wide: 0.1825\n",
            "  world: 0.1825\n",
            "\n",
            "document #3: About Us Anushka Avni Internat...\n",
            "  aai: 0.1825\n",
            "  agro: 0.1825\n",
            "  anushka: 0.1382\n",
            "  assortment: 0.1825\n",
            "  available: 0.1729\n",
            "  avni: 0.1382\n",
            "  best: 0.2225\n",
            "  buyer: 0.1825\n",
            "  come: 0.1645\n",
            "  exporter: 0.1569\n",
            "  feel: 0.1825\n",
            "  follow: 0.2065\n",
            "  huge: 0.1825\n",
            "  international: 0.1382\n",
            "  market: 0.1825\n",
            "  offer: 0.1825\n",
            "  one: 0.1501\n",
            "  pleasure: 0.1825\n",
            "  practice: 0.2225\n",
            "  presenting: 0.1825\n",
            "  product: 0.1645\n",
            "  proud: 0.1825\n",
            "  quality: 0.1729\n",
            "  read: 0.2225\n",
            "  recognizing: 0.1825\n",
            "  renowned: 0.1825\n",
            "  standard: 0.1825\n",
            "  supplier: 0.1569\n",
            "  take: 0.1825\n",
            "  wide: 0.1825\n",
            "  world: 0.1825\n",
            "\n",
            "document #4: White Onions from Anushka Avni...\n",
            "  10kg: 0.0956\n",
            "  15kg: 0.0956\n",
            "  17kg: 0.0956\n",
            "  18kg: 0.0956\n",
            "  20ft: 0.0956\n",
            "  20kg: 0.0956\n",
            "  25kg: 0.0956\n",
            "  28: 0.0956\n",
            "  30kg: 0.0956\n",
            "  3kg: 0.0956\n",
            "  40ft: 0.0956\n",
            "  50: 0.0956\n",
            "  5kg: 0.0956\n",
            "  60: 0.0956\n",
            "  9kg: 0.0956\n",
            "  ability: 0.0784\n",
            "  acclaimed: 0.1169\n",
            "  anushka: 0.0594\n",
            "  avni: 0.0594\n",
            "  bag: 0.1663\n",
            "  benefit: 0.1169\n",
            "  container: 0.1486\n",
            "  cuisine: 0.1169\n",
            "  different: 0.1169\n",
            "  exporter: 0.0675\n",
            "  fresh: 0.1486\n",
            "  health: 0.1045\n",
            "  international: 0.0594\n",
            "  jute: 0.0956\n",
            "  kind: 0.0956\n",
            "  like: 0.0832\n",
            "  load: 0.0784\n",
            "  major: 0.0888\n",
            "  mesh: 0.0956\n",
            "  mm: 0.3825\n",
            "  mt: 0.1913\n",
            "  odo: 0.0956\n",
            "  onion: 0.5326\n",
            "  packaging: 0.0743\n",
            "  per: 0.1486\n",
            "  pink: 0.1045\n",
            "  red: 0.1486\n",
            "  refer: 0.0956\n",
            "  size: 0.0743\n",
            "  supplier: 0.0675\n",
            "  used: 0.0832\n",
            "  white: 0.2869\n",
            "  widely: 0.1045\n",
            "\n",
            "document #5: Anushka Avni International (AA...\n",
            "  aai: 0.2029\n",
            "  agro: 0.2029\n",
            "  anushka: 0.1536\n",
            "  assortment: 0.2029\n",
            "  available: 0.1922\n",
            "  avni: 0.1536\n",
            "  buyer: 0.2029\n",
            "  come: 0.1829\n",
            "  exporter: 0.1745\n",
            "  feel: 0.2029\n",
            "  huge: 0.2029\n",
            "  international: 0.1536\n",
            "  market: 0.2029\n",
            "  offer: 0.2029\n",
            "  one: 0.1669\n",
            "  pleasure: 0.2029\n",
            "  presenting: 0.2029\n",
            "  product: 0.1829\n",
            "  proud: 0.2029\n",
            "  quality: 0.1922\n",
            "  recognizing: 0.2029\n",
            "  renowned: 0.2029\n",
            "  standard: 0.2029\n",
            "  supplier: 0.1745\n",
            "  take: 0.2029\n",
            "  wide: 0.2029\n",
            "  world: 0.2029\n",
            "\n",
            "document #6: To a botanist, a fruit is an e...\n",
            "  apple: 0.1984\n",
            "  apricot: 0.1984\n",
            "  bean: 0.1984\n",
            "  botanist: 0.1773\n",
            "  corn: 0.1984\n",
            "  cucumber: 0.1984\n",
            "  develops: 0.1984\n",
            "  eggplant: 0.1984\n",
            "  entity: 0.1984\n",
            "  fertilized: 0.1984\n",
            "  flower: 0.1984\n",
            "  fruit: 0.2662\n",
            "  kernel: 0.1984\n",
            "  mango: 0.1984\n",
            "  mean: 0.1984\n",
            "  melon: 0.1984\n",
            "  ovary: 0.1984\n",
            "  pea: 0.1984\n",
            "  peach: 0.1984\n",
            "  pear: 0.1984\n",
            "  pepper: 0.1984\n",
            "  pod: 0.1984\n",
            "  pumpkin: 0.1984\n",
            "  squash: 0.1984\n",
            "  tomato: 0.1773\n",
            "\n",
            "document #7: Nutrition is the biochemical a...\n",
            "  absorption: 0.1684\n",
            "  also: 0.1198\n",
            "  assimilation: 0.1684\n",
            "  biochemical: 0.1684\n",
            "  biosynthesis: 0.1684\n",
            "  called: 0.1278\n",
            "  catabolism: 0.1684\n",
            "  excretion: 0.1684\n",
            "  includes: 0.1684\n",
            "  ingestion: 0.1684\n",
            "  intake: 0.1684\n",
            "  life: 0.1377\n",
            "  nutrition: 0.4132\n",
            "  nutritional: 0.1684\n",
            "  organism: 0.1377\n",
            "  physiological: 0.3368\n",
            "  process: 0.3368\n",
            "  science: 0.4132\n",
            "  study: 0.1505\n",
            "  support: 0.1684\n",
            "  us: 0.1684\n",
            "\n",
            "document #8: Nutrients are substances used ...\n",
            "  animal: 0.1226\n",
            "  carbohydrate: 0.2452\n",
            "  class: 0.1226\n",
            "  dietary: 0.2452\n",
            "  either: 0.1226\n",
            "  fat: 0.2452\n",
            "  fiber: 0.2452\n",
            "  gram: 0.1226\n",
            "  grouped: 0.1226\n",
            "  grow: 0.1226\n",
            "  human: 0.1095\n",
            "  including: 0.1095\n",
            "  macronutrients: 0.1226\n",
            "  major: 0.0931\n",
            "  microgram: 0.1226\n",
            "  micronutrient: 0.1226\n",
            "  milligram: 0.1226\n",
            "  mineral: 0.2452\n",
            "  needed: 0.2452\n",
            "  nutrient: 0.3678\n",
            "  organism: 0.1002\n",
            "  protein: 0.2190\n",
            "  quantity: 0.2452\n",
            "  relevant: 0.1226\n",
            "  reproduce: 0.1226\n",
            "  seven: 0.1226\n",
            "  substance: 0.1226\n",
            "  survive: 0.1226\n",
            "  used: 0.0872\n",
            "  vitamin: 0.2452\n",
            "  water: 0.2452\n",
            "\n",
            "document #9: In nutrition, the diet of an o...\n",
            "  availability: 0.2355\n",
            "  determined: 0.3103\n",
            "  diet: 0.2772\n",
            "  eats: 0.3103\n",
            "  food: 0.5075\n",
            "  largely: 0.3103\n",
            "  nutrition: 0.2537\n",
            "  organism: 0.2537\n",
            "  palatability: 0.3103\n",
            "  sum: 0.3103\n",
            "\n",
            "document #10: Canada's Food Guide is a nutri...\n",
            "  2007: 0.0849\n",
            "  also: 0.0604\n",
            "  basic: 0.0849\n",
            "  behaviour: 0.0849\n",
            "  behind: 0.0849\n",
            "  canada: 0.3223\n",
            "  canadian: 0.0759\n",
            "  choosing: 0.0849\n",
            "  come: 0.0513\n",
            "  day: 0.0759\n",
            "  designed: 0.0849\n",
            "  diet: 0.0759\n",
            "  eating: 0.0849\n",
            "  education: 0.0849\n",
            "  follow: 0.0645\n",
            "  food: 0.4860\n",
            "  form: 0.0849\n",
            "  fruit: 0.0569\n",
            "  government: 0.0849\n",
            "  grain: 0.0849\n",
            "  guide: 0.3396\n",
            "  habit: 0.0849\n",
            "  health: 0.1517\n",
            "  healthy: 0.3396\n",
            "  help: 0.0849\n",
            "  highly: 0.0849\n",
            "  including: 0.0759\n",
            "  income: 0.0849\n",
            "  increase: 0.0849\n",
            "  lifestyle: 0.0849\n",
            "  limiting: 0.0849\n",
            "  number: 0.0694\n",
            "  nutrition: 0.0694\n",
            "  often: 0.0759\n",
            "  people: 0.1698\n",
            "  plant: 0.0694\n",
            "  plenty: 0.0849\n",
            "  processed: 0.0849\n",
            "  produced: 0.0849\n",
            "  promote: 0.0849\n",
            "  protein: 0.1517\n",
            "  publication: 0.0849\n",
            "  recommends: 0.2547\n",
            "  reported: 0.0849\n",
            "  requested: 0.0849\n",
            "  second: 0.0849\n",
            "  state: 0.0759\n",
            "  tax: 0.0849\n",
            "  tool: 0.0759\n",
            "  variety: 0.0694\n",
            "  vegetable: 0.0849\n",
            "  website: 0.0849\n",
            "  whole: 0.0849\n",
            "\n",
            "document #11: UK, Nether Land, Russia, Canad...\n",
            "  arabia: 0.2346\n",
            "  bahrain: 0.2346\n",
            "  bangladesh: 0.2346\n",
            "  canada: 0.1781\n",
            "  hongkong: 0.2346\n",
            "  land: 0.2346\n",
            "  lanka: 0.2346\n",
            "  malaysia: 0.2096\n",
            "  maldives: 0.2346\n",
            "  mauritius: 0.2346\n",
            "  nether: 0.2346\n",
            "  oman: 0.2346\n",
            "  qatar: 0.2346\n",
            "  russia: 0.2346\n",
            "  saudi: 0.2346\n",
            "  singapore: 0.2096\n",
            "  sri: 0.2346\n",
            "  uae: 0.2346\n",
            "  uk: 0.2346\n",
            "\n",
            "document #12: Canadian Industry Statistics (...\n",
            "  analysis: 0.2866\n",
            "  canada: 0.2176\n",
            "  canadian: 0.2561\n",
            "  ci: 0.2866\n",
            "  data: 0.2561\n",
            "  economic: 0.2866\n",
            "  indicator: 0.2866\n",
            "  industry: 0.5732\n",
            "  many: 0.2866\n",
            "  statistic: 0.2866\n",
            "\n",
            "document #13: Red Onions from Anushka Avni I...\n",
            "  10kg: 0.0867\n",
            "  15kg: 0.0867\n",
            "  17kg: 0.0867\n",
            "  18kg: 0.0867\n",
            "  20ft: 0.0867\n",
            "  20kg: 0.0867\n",
            "  25kg: 0.0867\n",
            "  28: 0.0867\n",
            "  30kg: 0.0867\n",
            "  3kg: 0.0867\n",
            "  40ft: 0.0867\n",
            "  50: 0.0867\n",
            "  5kg: 0.0867\n",
            "  60: 0.0867\n",
            "  9kg: 0.0867\n",
            "  ability: 0.0711\n",
            "  anushka: 0.0538\n",
            "  avni: 0.0538\n",
            "  bag: 0.1507\n",
            "  called: 0.0805\n",
            "  container: 0.1347\n",
            "  cultivar: 0.0947\n",
            "  exporter: 0.0611\n",
            "  flesh: 0.0947\n",
            "  fresh: 0.0674\n",
            "  indian: 0.0947\n",
            "  international: 0.0538\n",
            "  jute: 0.0867\n",
            "  kind: 0.0867\n",
            "  like: 0.0754\n",
            "  load: 0.0711\n",
            "  major: 0.0805\n",
            "  mesh: 0.0867\n",
            "  mm: 0.3467\n",
            "  mt: 0.1733\n",
            "  odo: 0.0867\n",
            "  onion: 0.5632\n",
            "  packaging: 0.0674\n",
            "  per: 0.1347\n",
            "  purple: 0.0947\n",
            "  purplish: 0.1060\n",
            "  red: 0.4041\n",
            "  refer: 0.0867\n",
            "  size: 0.0674\n",
            "  skin: 0.0805\n",
            "  sometimes: 0.0947\n",
            "  supplier: 0.0611\n",
            "  tinged: 0.0947\n",
            "  white: 0.1733\n",
            "\n",
            "document #14: Berry Size: 18mm and above Pac...\n",
            "  18mm: 0.1284\n",
            "  2040: 0.1284\n",
            "  2400: 0.1284\n",
            "  3400: 0.1284\n",
            "  500: 0.1284\n",
            "  ability: 0.0964\n",
            "  april: 0.1175\n",
            "  availability: 0.1091\n",
            "  bag: 0.2044\n",
            "  berry: 0.1175\n",
            "  carry: 0.2568\n",
            "  carton: 0.4088\n",
            "  container: 0.2740\n",
            "  december: 0.1284\n",
            "  february: 0.1175\n",
            "  gm: 0.1284\n",
            "  january: 0.1175\n",
            "  kg: 0.4088\n",
            "  kilo: 0.2568\n",
            "  load: 0.0964\n",
            "  loose: 0.2350\n",
            "  march: 0.1175\n",
            "  packaging: 0.0913\n",
            "  packing: 0.1175\n",
            "  per: 0.2740\n",
            "  punnets10: 0.1284\n",
            "  size: 0.1826\n",
            "\n",
            "document #15: Pink Onions from Anushka Avni ...\n",
            "  10kg: 0.0823\n",
            "  15kg: 0.0823\n",
            "  17kg: 0.0823\n",
            "  18kg: 0.0823\n",
            "  20ft: 0.0823\n",
            "  20kg: 0.0823\n",
            "  25kg: 0.0823\n",
            "  28: 0.0823\n",
            "  30kg: 0.0823\n",
            "  3kg: 0.0823\n",
            "  40ft: 0.0823\n",
            "  50: 0.0823\n",
            "  5kg: 0.0823\n",
            "  60: 0.0823\n",
            "  9kg: 0.0823\n",
            "  ability: 0.0675\n",
            "  anushka: 0.0511\n",
            "  avni: 0.0511\n",
            "  bag: 0.1431\n",
            "  called: 0.0764\n",
            "  container: 0.1279\n",
            "  cultivar: 0.0899\n",
            "  exporter: 0.0581\n",
            "  flesh: 0.0899\n",
            "  fresh: 0.0640\n",
            "  indian: 0.0899\n",
            "  international: 0.0511\n",
            "  jute: 0.0823\n",
            "  kind: 0.0823\n",
            "  like: 0.0716\n",
            "  load: 0.0675\n",
            "  major: 0.0764\n",
            "  mesh: 0.0823\n",
            "  mm: 0.3292\n",
            "  mt: 0.1646\n",
            "  odo: 0.0823\n",
            "  onion: 0.6111\n",
            "  packaging: 0.0640\n",
            "  per: 0.1279\n",
            "  pink: 0.3596\n",
            "  red: 0.1919\n",
            "  refer: 0.0823\n",
            "  size: 0.0640\n",
            "  skin: 0.0764\n",
            "  sometimes: 0.0899\n",
            "  summer: 0.1006\n",
            "  supplier: 0.0581\n",
            "  tinged: 0.0899\n",
            "  white: 0.1646\n",
            "\n",
            "document #16: Anushka Avni International (AA...\n",
            "  aai: 0.0832\n",
            "  across: 0.1240\n",
            "  agro: 0.0832\n",
            "  anushka: 0.0630\n",
            "  assortment: 0.0832\n",
            "  available: 0.0788\n",
            "  avni: 0.0630\n",
            "  aware: 0.1240\n",
            "  background: 0.1240\n",
            "  best: 0.3043\n",
            "  buyer: 0.0832\n",
            "  client: 0.1108\n",
            "  come: 0.0750\n",
            "  company: 0.2216\n",
            "  consider: 0.1240\n",
            "  deliver: 0.1240\n",
            "  demand: 0.2481\n",
            "  destination: 0.1240\n",
            "  domestic: 0.1240\n",
            "  established: 0.1240\n",
            "  evolving: 0.1240\n",
            "  exporter: 0.0715\n",
            "  exportingagro: 0.1240\n",
            "  fact: 0.1240\n",
            "  feel: 0.0832\n",
            "  final: 0.1240\n",
            "  follow: 0.0941\n",
            "  forproviding: 0.1240\n",
            "  handling: 0.1240\n",
            "  harvest: 0.1240\n",
            "  horticultureand: 0.1240\n",
            "  huge: 0.0832\n",
            "  initiative: 0.1240\n",
            "  international: 0.0630\n",
            "  internationalmarket: 0.1240\n",
            "  keep: 0.1240\n",
            "  market: 0.1664\n",
            "  moreover: 0.1240\n",
            "  offer: 0.0832\n",
            "  ofthe: 0.1240\n",
            "  one: 0.0684\n",
            "  perishable: 0.1240\n",
            "  pleasure: 0.0832\n",
            "  practice: 0.1014\n",
            "  presenting: 0.0832\n",
            "  product: 0.1500\n",
            "  professional: 0.1240\n",
            "  proud: 0.0832\n",
            "  quality: 0.2365\n",
            "  recognizing: 0.0832\n",
            "  renowned: 0.0832\n",
            "  requirement: 0.1108\n",
            "  standard: 0.0832\n",
            "  strong: 0.1240\n",
            "  supplier: 0.0715\n",
            "  supplying: 0.1240\n",
            "  take: 0.1664\n",
            "  thecustomers: 0.2481\n",
            "  thoroughly: 0.1240\n",
            "  till: 0.1240\n",
            "  wide: 0.0832\n",
            "  world: 0.0832\n",
            "\n",
            "document #17: We are one of the leading orga...\n",
            "  bulk: 0.2353\n",
            "  client: 0.2353\n",
            "  customer: 0.2633\n",
            "  delivering: 0.2633\n",
            "  detail: 0.1999\n",
            "  engaged: 0.2633\n",
            "  fresh: 0.1674\n",
            "  leading: 0.2633\n",
            "  malaysia: 0.2353\n",
            "  manufacture: 0.2633\n",
            "  one: 0.1453\n",
            "  onion: 0.1999\n",
            "  organization: 0.2353\n",
            "  philippine: 0.2633\n",
            "  product: 0.1592\n",
            "  quality: 0.1674\n",
            "  requirement: 0.2353\n",
            "  singapore: 0.2353\n",
            "  vietnam: 0.2633\n",
            "\n",
            "document #18: Fresh Tomatoes from Anushka Av...\n",
            "  actively: 0.2104\n",
            "  anushka: 0.1068\n",
            "  avni: 0.1068\n",
            "  carton: 0.1496\n",
            "  chutney: 0.2104\n",
            "  detail: 0.1597\n",
            "  emerged: 0.2104\n",
            "  enhancer: 0.2104\n",
            "  exporting: 0.2104\n",
            "  free: 0.2104\n",
            "  fresh: 0.1337\n",
            "  international: 0.1068\n",
            "  kg: 0.2992\n",
            "  one: 0.1161\n",
            "  organization: 0.1880\n",
            "  packing: 0.1720\n",
            "  participating: 0.2104\n",
            "  preservative: 0.2104\n",
            "  product: 0.1272\n",
            "  pure: 0.2104\n",
            "  red: 0.1337\n",
            "  reputed: 0.2104\n",
            "  suppling: 0.2104\n",
            "  taste: 0.1597\n",
            "  tomato: 0.3759\n",
            "  useful: 0.2104\n",
            "\n",
            "document #19: Anushka Avni International (AA...\n",
            "  aai: 0.2029\n",
            "  agro: 0.2029\n",
            "  anushka: 0.1536\n",
            "  assortment: 0.2029\n",
            "  available: 0.1922\n",
            "  avni: 0.1536\n",
            "  buyer: 0.2029\n",
            "  come: 0.1829\n",
            "  exporter: 0.1745\n",
            "  feel: 0.2029\n",
            "  huge: 0.2029\n",
            "  international: 0.1536\n",
            "  market: 0.2029\n",
            "  offer: 0.2029\n",
            "  one: 0.1669\n",
            "  pleasure: 0.2029\n",
            "  presenting: 0.2029\n",
            "  product: 0.1829\n",
            "  proud: 0.2029\n",
            "  quality: 0.1922\n",
            "  recognizing: 0.2029\n",
            "  renowned: 0.2029\n",
            "  standard: 0.2029\n",
            "  supplier: 0.1745\n",
            "  take: 0.2029\n",
            "  wide: 0.2029\n",
            "  world: 0.2029\n",
            "\n",
            "document #20: Welcome to Anushka Avni Intern...\n",
            "  aai: 0.3396\n",
            "  agro: 0.1698\n",
            "  anushka: 0.2572\n",
            "  assortment: 0.1698\n",
            "  available: 0.1609\n",
            "  avni: 0.2572\n",
            "  buyer: 0.1698\n",
            "  come: 0.1531\n",
            "  exporter: 0.1461\n",
            "  feel: 0.1698\n",
            "  huge: 0.1698\n",
            "  international: 0.2572\n",
            "  market: 0.1698\n",
            "  offer: 0.1698\n",
            "  one: 0.1397\n",
            "  pleasure: 0.1698\n",
            "  presenting: 0.1698\n",
            "  product: 0.1531\n",
            "  proud: 0.1698\n",
            "  quality: 0.1609\n",
            "  recognizing: 0.1698\n",
            "  renowned: 0.1698\n",
            "  standard: 0.1698\n",
            "  supplier: 0.1461\n",
            "  take: 0.1698\n",
            "  welcome: 0.2532\n",
            "  wide: 0.1698\n",
            "  world: 0.1698\n",
            "\n",
            "document #21: Thomson Seedless These grapes ...\n",
            "  16mm: 0.2216\n",
            "  account: 0.2216\n",
            "  berry: 0.1812\n",
            "  bulk: 0.1980\n",
            "  crunchy: 0.2216\n",
            "  export: 0.2216\n",
            "  grape: 0.3624\n",
            "  india: 0.1980\n",
            "  seedless: 0.5437\n",
            "  size: 0.1408\n",
            "  table: 0.2216\n",
            "  thomson: 0.4432\n",
            "\n",
            "document #22: Black Sharad Seedless Grapes C...\n",
            "  18mm: 0.1122\n",
            "  2040: 0.1122\n",
            "  2400: 0.1122\n",
            "  3400: 0.1122\n",
            "  500: 0.1122\n",
            "  ability: 0.0843\n",
            "  april: 0.1027\n",
            "  availability: 0.0954\n",
            "  bag: 0.1787\n",
            "  berry: 0.2055\n",
            "  black: 0.2245\n",
            "  carry: 0.2245\n",
            "  carton: 0.3574\n",
            "  container: 0.2395\n",
            "  crisp: 0.1256\n",
            "  december: 0.1122\n",
            "  february: 0.1027\n",
            "  gm: 0.1122\n",
            "  grape: 0.2055\n",
            "  january: 0.1027\n",
            "  kg: 0.3574\n",
            "  kilo: 0.2245\n",
            "  load: 0.0843\n",
            "  loose: 0.2055\n",
            "  march: 0.1027\n",
            "  packaging: 0.0798\n",
            "  packing: 0.1027\n",
            "  per: 0.2395\n",
            "  punnets10: 0.1122\n",
            "  purple: 0.1122\n",
            "  seedless: 0.1027\n",
            "  shade: 0.1256\n",
            "  sharad: 0.1256\n",
            "  size: 0.1597\n",
            "  taste: 0.0954\n",
            "  usually: 0.1256\n",
            "  vary: 0.1256\n",
            "\n",
            "document #23: Flame / Red seedless grapesFla...\n",
            "  along: 0.3859\n",
            "  flame: 0.3859\n",
            "  grape: 0.3156\n",
            "  grapesflame: 0.3859\n",
            "  one: 0.2129\n",
            "  popular: 0.3859\n",
            "  red: 0.2453\n",
            "  seedless: 0.3156\n",
            "  variety: 0.3156\n",
            "\n",
            "document #24: A Dictionary in Python is an u...\n",
            "  collection: 0.1363\n",
            "  data: 0.4088\n",
            "  dictionary: 0.3050\n",
            "  element: 0.1525\n",
            "  hold: 0.3050\n",
            "  key: 0.1525\n",
            "  like: 0.1085\n",
            "  map: 0.1525\n",
            "  pair: 0.1525\n",
            "  python: 0.1525\n",
            "  single: 0.1525\n",
            "  store: 0.1525\n",
            "  type: 0.1525\n",
            "  unlike: 0.1525\n",
            "  unordered: 0.1525\n",
            "  used: 0.1085\n",
            "  value: 0.6100\n",
            "\n",
            "document #25: Botany originated in prehistor...\n",
            "  1540s: 0.1057\n",
            "  1753: 0.1057\n",
            "  academic: 0.1057\n",
            "  attached: 0.2113\n",
            "  beginning: 0.0944\n",
            "  binomial: 0.1057\n",
            "  biological: 0.1057\n",
            "  botanical: 0.2113\n",
            "  botany: 0.0944\n",
            "  branch: 0.0944\n",
            "  carl: 0.1057\n",
            "  catalogue: 0.1057\n",
            "  collection: 0.0944\n",
            "  contained: 0.1057\n",
            "  cultivate: 0.1057\n",
            "  day: 0.0944\n",
            "  describe: 0.1057\n",
            "  earliest: 0.1057\n",
            "  early: 0.1057\n",
            "  edible: 0.1057\n",
            "  effort: 0.2113\n",
            "  facilitated: 0.1057\n",
            "  first: 0.0944\n",
            "  forerunner: 0.1057\n",
            "  founded: 0.1057\n",
            "  garden: 0.4227\n",
            "  herbalism: 0.1057\n",
            "  human: 0.0944\n",
            "  identify: 0.1057\n",
            "  importance: 0.1057\n",
            "  later: 0.1057\n",
            "  led: 0.1057\n",
            "  linnaeus: 0.1057\n",
            "  making: 0.1057\n",
            "  medical: 0.1057\n",
            "  medicinal: 0.1057\n",
            "  medieval: 0.1057\n",
            "  monastery: 0.1057\n",
            "  naming: 0.1057\n",
            "  nomenclature: 0.1057\n",
            "  often: 0.0944\n",
            "  oldest: 0.1057\n",
            "  one: 0.1166\n",
            "  onwards: 0.1057\n",
            "  originated: 0.1057\n",
            "  padua: 0.1057\n",
            "  physic: 0.1057\n",
            "  plant: 0.3456\n",
            "  poisonous: 0.1057\n",
            "  prehistory: 0.1057\n",
            "  remains: 0.1057\n",
            "  science: 0.0864\n",
            "  specie: 0.1057\n",
            "  study: 0.0944\n",
            "  system: 0.1057\n",
            "  taxonomy: 0.1057\n",
            "  university: 0.1057\n",
            "  use: 0.0944\n",
            "\n",
            "document #26: Semantic similarity is a metri...\n",
            "  according: 0.1442\n",
            "  based: 0.1442\n",
            "  comparison: 0.1442\n",
            "  concept: 0.1442\n",
            "  content: 0.1288\n",
            "  defined: 0.1442\n",
            "  describing: 0.1442\n",
            "  description: 0.1442\n",
            "  distance: 0.1442\n",
            "  document: 0.1442\n",
            "  estimate: 0.1442\n",
            "  idea: 0.1442\n",
            "  information: 0.1442\n",
            "  instance: 0.1442\n",
            "  item: 0.1442\n",
            "  language: 0.1442\n",
            "  lexicographical: 0.1442\n",
            "  likeness: 0.1442\n",
            "  mathematical: 0.1442\n",
            "  meaning: 0.2884\n",
            "  metric: 0.1442\n",
            "  nature: 0.1442\n",
            "  numerical: 0.1442\n",
            "  obtained: 0.1442\n",
            "  opposed: 0.1442\n",
            "  relationship: 0.1442\n",
            "  semantic: 0.4326\n",
            "  set: 0.1442\n",
            "  similarity: 0.2884\n",
            "  strength: 0.1442\n",
            "  supporting: 0.1442\n",
            "  term: 0.1442\n",
            "  tool: 0.1288\n",
            "  unit: 0.1442\n",
            "  used: 0.1025\n",
            "\n",
            "document #27: Botany, also called plant scie...\n",
            "  also: 0.1309\n",
            "  biology: 0.3681\n",
            "  botanist: 0.1644\n",
            "  botany: 0.1644\n",
            "  branch: 0.1644\n",
            "  called: 0.1397\n",
            "  field: 0.1841\n",
            "  life: 0.1505\n",
            "  phytologist: 0.1841\n",
            "  phytology: 0.1841\n",
            "  plant: 0.6020\n",
            "  science: 0.3010\n",
            "  scientist: 0.3681\n",
            "  specialises: 0.1841\n",
            "\n",
            "document #28: The Ford Bronco is a model lin...\n",
            "  1966: 0.1007\n",
            "  1996: 0.1007\n",
            "  2021: 0.1007\n",
            "  available: 0.0640\n",
            "  badlands: 0.1007\n",
            "  bank: 0.1007\n",
            "  base: 0.1007\n",
            "  beginning: 0.0899\n",
            "  bend: 0.1007\n",
            "  big: 0.1007\n",
            "  black: 0.0899\n",
            "  bronco: 0.4027\n",
            "  canada: 0.1528\n",
            "  come: 0.0609\n",
            "  company: 0.0899\n",
            "  delivery: 0.1007\n",
            "  developed: 0.1007\n",
            "  diamond: 0.1007\n",
            "  first: 0.1799\n",
            "  five: 0.1007\n",
            "  ford: 0.3020\n",
            "  generation: 0.2014\n",
            "  line: 0.2014\n",
            "  manufactured: 0.1007\n",
            "  marketed: 0.1007\n",
            "  model: 0.5034\n",
            "  outer: 0.1007\n",
            "  six: 0.1007\n",
            "  sixth: 0.1007\n",
            "  sold: 0.2014\n",
            "  sport: 0.1007\n",
            "  spring: 0.1007\n",
            "  suv: 0.1007\n",
            "  utility: 0.1007\n",
            "  vehicle: 0.1007\n",
            "  version: 0.1007\n",
            "  wildtrak: 0.1007\n",
            "  year: 0.2014\n",
            "\n",
            "document #29: Fruit dishes are those that us...\n",
            "  also: 0.1669\n",
            "  condiment: 0.2347\n",
            "  dish: 0.2097\n",
            "  fruit: 0.4722\n",
            "  included: 0.2347\n",
            "  ingredient: 0.4695\n",
            "  list: 0.2347\n",
            "  prepared: 0.2347\n",
            "  primary: 0.4695\n",
            "  use: 0.2097\n",
            "\n",
            "document #30: Neuro linguistic programming (...\n",
            "  1970s: 0.2306\n",
            "  approach: 0.2306\n",
            "  bandler: 0.2306\n",
            "  california: 0.2306\n",
            "  communication: 0.2306\n",
            "  created: 0.2306\n",
            "  development: 0.2306\n",
            "  grinder: 0.2306\n",
            "  john: 0.2306\n",
            "  linguistic: 0.2306\n",
            "  neuro: 0.2306\n",
            "  nlp: 0.2306\n",
            "  personal: 0.2306\n",
            "  programming: 0.2306\n",
            "  pseudoscientific: 0.2306\n",
            "  psychotherapy: 0.2306\n",
            "  richard: 0.2306\n",
            "  state: 0.2061\n",
            "  united: 0.2306\n",
            "\n",
            "document #31: A fruit serving bowl is a roun...\n",
            "  bottom: 0.1446\n",
            "  bowl: 0.5785\n",
            "  cap: 0.1446\n",
            "  center: 0.1446\n",
            "  characteristically: 0.1446\n",
            "  concentrated: 0.1446\n",
            "  container: 0.0919\n",
            "  content: 0.1292\n",
            "  curve: 0.1446\n",
            "  dish: 0.1292\n",
            "  edge: 0.1446\n",
            "  especially: 0.1446\n",
            "  food: 0.2365\n",
            "  force: 0.1446\n",
            "  forming: 0.1446\n",
            "  fruit: 0.0970\n",
            "  gravity: 0.1446\n",
            "  holding: 0.1446\n",
            "  interior: 0.1446\n",
            "  like: 0.1029\n",
            "  liquid: 0.1446\n",
            "  loose: 0.1183\n",
            "  make: 0.1446\n",
            "  naturally: 0.1446\n",
            "  prepare: 0.1446\n",
            "  round: 0.1446\n",
            "  seamless: 0.1446\n",
            "  serve: 0.1446\n",
            "  serving: 0.1446\n",
            "  shaped: 0.1446\n",
            "  spherical: 0.1446\n",
            "  suited: 0.1446\n",
            "  typically: 0.1446\n",
            "  used: 0.1029\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# pass `lemmatizer_vectorizer` and `lemmatizer_document_vectors` already computed above\n",
        "top_N_documents_similarity_scores(\n",
        "    lemmatized_vectorizer,\n",
        "    lemmatized_document_vectors, queries, 5);\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dLWPHTEsgTN",
        "outputId": "d99f709f-47f0-40fb-9d7b-1aafee0f9236"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query: fruits\n",
            ">> score: 0.4722 for document #29: Fruit dishes are those that us...\n",
            ">> score: 0.2662 for document #6: To a botanist, a fruit is an e...\n",
            ">> score: 0.1628 for document #0: Fresh Pomegranate from Anushka...\n",
            ">> score: 0.0970 for document #31: A fruit serving bowl is a roun...\n",
            ">> score: 0.0569 for document #10: Canada's Food Guide is a nutri...\n",
            "\n",
            "query: vegetables\n",
            ">> score: 0.0849 for document #10: Canada's Food Guide is a nutri...\n",
            ">> score: 0.0000 for document #31: A fruit serving bowl is a roun...\n",
            ">> score: 0.0000 for document #30: Neuro linguistic programming (...\n",
            ">> score: 0.0000 for document #1: Fresh Pomegranate Arakta from ...\n",
            ">> score: 0.0000 for document #2: About Us Anushka Avni Internat...\n",
            "\n",
            "query: healthy foods in Canada\n",
            ">> score: 0.6552 for document #10: Canada's Food Guide is a nutri...\n",
            ">> score: 0.2770 for document #9: In nutrition, the diet of an o...\n",
            ">> score: 0.1291 for document #31: A fruit serving bowl is a roun...\n",
            ">> score: 0.1102 for document #12: Canadian Industry Statistics (...\n",
            ">> score: 0.0902 for document #11: UK, Nether Land, Russia, Canad...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What impact did the text cleaning / preprocessing have on your results?"
      ],
      "metadata": {
        "id": "eg7AQ9wGy1BA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Response:\n",
        "\n",
        "1. Removal of stop words (\"the\", \"is\", \"and\", etc.) eliminates non-informative terms that would otherwise add noise to the TF-IDF matrix\n",
        "2. Gives higher TF-IDF weights for meaningful terms, making them more influential in similarity calculations\n",
        "3. Lemmatization helps group different word forms for better generalization\n",
        "4. Vocabularty size:\n",
        "  - Before preprocessing: ~616 terms\n",
        "  - After preprocessing: ~565 terms\n",
        "5. Similarity Scores (for query \"fruits\")\n",
        "  - Without preprocessing: Lower scores due to mismatches (\"fruits\" vs. \"fruit\")\n",
        "  - With preprocessing: Higher scores, better alignment"
      ],
      "metadata": {
        "id": "NuKB3P3dtmVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"len(vocabulary): \", len(vocabulary))\n",
        "\n",
        "print(\"len(lemmatized_vocabulary): \", len(lemmatized_vocabulary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyr4k9liwwY8",
        "outputId": "6b335d17-f3a2-4855-9c5d-e4f9d028b962"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(vocabulary):  616\n",
            "len(lemmatized_vocabulary):  565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8V2kx6Epnxq"
      },
      "source": [
        "# Experiment 2: Semantic matching using GloVe embeddings\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGBg_Roo8FvP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9edf6a39-893d-456c-8992-d4ef54bcbdaf"
      },
      "source": [
        "# if you decide to use the gensim library and the sample codes below,\n",
        "# you would need gensim version >=4.0.1 to be installed\n",
        "# !pip install  gensim==4.0.1\n",
        "import gensim\n",
        "print(gensim.__version__)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oywLsqBYrayZ"
      },
      "source": [
        "import logging\n",
        "import json\n",
        "import logging\n",
        "from re import sub\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import gensim.downloader as api\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import TfidfModel\n",
        "from gensim.similarities import WordEmbeddingSimilarityIndex\n",
        "from gensim.similarities import SparseTermSimilarityMatrix\n",
        "from gensim.similarities import SoftCosineSimilarity"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa0dlD102lbp"
      },
      "source": [
        "# optional, but it helps\n",
        "import logging\n",
        "\n",
        "# Initialize logging.\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.WARNING)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwQBtaxk5rXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b772529-ddd5-4e3f-c71a-f3eb6ff18736"
      },
      "source": [
        "import nltk\n",
        "\n",
        "# Import and download stopwords from NLTK.\n",
        "nltk.download('stopwords')  # Download stopwords list.\n",
        "stopwords = set(nltk.corpus.stopwords.words(\"english\"))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mlGyZeZ2Nle"
      },
      "source": [
        "def preprocess(doc):\n",
        "    # Tokenize, clean up input document string\n",
        "    doc = sub(r'<img[^<>]+(>|$)', \" image_token \", doc)\n",
        "    # you may decide to add additional steps here\n",
        "    return [token for token in simple_preprocess(doc, min_len=0, max_len=float(\"inf\")) if token not in stopwords]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP1s_4hMpqAn"
      },
      "source": [
        "# Load test data\n",
        "with open('sample_repository.json') as in_file:\n",
        "    repo_data = json.load(in_file)\n",
        "\n",
        "titles = [item[0] for item in repo_data['data']]\n",
        "documents = [item[1] for item in repo_data['data']]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaVXOXGDpqD5"
      },
      "source": [
        "# query_s = 'Your queries here'\n",
        "\n",
        "# Preprocess the documents, including the query string\n",
        "corpus = [preprocess(document) for document in documents]\n",
        "\n",
        "# to be iterated in new function below...\n",
        "# query = preprocess(query_s)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR_F5zkipqH7"
      },
      "source": [
        "# Download and load the GloVe word vector embeddings\n",
        "if 'glove' not in locals():  # only load if not already in memory\n",
        "    glove = api.load(\"glove-wiki-gigaword-50\")\n",
        "\n",
        "similarity_index = WordEmbeddingSimilarityIndex(glove)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtWEI622pqLa"
      },
      "source": [
        "def dictionary_tfidf_similarity_matrix(query):\n",
        "  # Build the term dictionary, TF-idf model\n",
        "  # Keep in mind that the search query must be in the dictionary as well, in case the terms do not overlap with the documents\n",
        "  dictionary = Dictionary(corpus+[query])\n",
        "  tfidf = TfidfModel(dictionary=dictionary)\n",
        "\n",
        "  # Create the term similarity matrix.\n",
        "  # The nonzero_limit enforces sparsity by limiting the number of non-zero terms in each column.\n",
        "  # In my case, I got best results by removing the default value of 100\n",
        "  similarity_matrix = SparseTermSimilarityMatrix(similarity_index, dictionary, tfidf)  # , nonzero_limit=None)\n",
        "\n",
        "  return dictionary, tfidf, similarity_matrix"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn9tPObFpqPJ"
      },
      "source": [
        "# Compute similarity measure between the query and the documents.\n",
        "\n",
        "def compute_similarity_query_documents(\n",
        "    dictionary: Dictionary,\n",
        "    tfidf : TfidfModel,\n",
        "    similarity_matrix : SparseTermSimilarityMatrix,\n",
        "    query):\n",
        "\n",
        "  query_tf = tfidf[dictionary.doc2bow(query)]\n",
        "\n",
        "  index = SoftCosineSimilarity(\n",
        "              tfidf[[dictionary.doc2bow(document) for document in corpus]],\n",
        "              similarity_matrix)\n",
        "\n",
        "  doc_similarity_scores = index[query_tf]\n",
        "  return doc_similarity_scores"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-XmAUHwpqSD"
      },
      "source": [
        "\n",
        "# for each query, output the similarity scores for the top 5 documents with\n",
        "# th highest score, and interpret your results\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_s = ['fruits', 'vegetables', 'healthy foods in Canada']\n",
        "\n",
        "for query in [preprocess(q) for q in query_s]:\n",
        "  dictionary, tfidf, similarity_matrix = dictionary_tfidf_similarity_matrix(query)\n",
        "  doc_similarity_scores = compute_similarity_query_documents(\n",
        "      dictionary,\n",
        "      tfidf,\n",
        "      similarity_matrix,\n",
        "      query)\n",
        "\n",
        "  top_indices = doc_similarity_scores.argsort()[::-1]\n",
        "\n",
        "  print()\n",
        "  print(f\"query: {query}\")\n",
        "  for index in top_indices[:5]:\n",
        "    print(f\">> score: {doc_similarity_scores[index]:.4f} for document #{index}: {documents[index][:30]}...\")\n",
        "  print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY5fHPzS-KT7",
        "outputId": "b3817f17-aa2c-4da6-e133-3d6e6d7f2168"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 568/568 [00:15<00:00, 35.88it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gensim/similarities/termsim.py:382: RuntimeWarning: divide by zero encountered in divide\n",
            "  normalized_corpus = np.multiply(corpus, 1.0 / corpus_norm)\n",
            "/usr/local/lib/python3.10/dist-packages/gensim/similarities/termsim.py:382: RuntimeWarning: invalid value encountered in multiply\n",
            "  normalized_corpus = np.multiply(corpus, 1.0 / corpus_norm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "query: ['fruits']\n",
            ">> score: 0.8839 for document #6: To a botanist, a fruit is an e...\n",
            ">> score: 0.8437 for document #31: A fruit serving bowl is a roun...\n",
            ">> score: 0.8437 for document #29: Fruit dishes are those that us...\n",
            ">> score: 0.8092 for document #0: Fresh Pomegranate from Anushka...\n",
            ">> score: 0.7613 for document #10: Canada's Food Guide is a nutri...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 568/568 [00:14<00:00, 39.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "query: ['vegetables']\n",
            ">> score: 0.8961 for document #6: To a botanist, a fruit is an e...\n",
            ">> score: 0.8104 for document #10: Canada's Food Guide is a nutri...\n",
            ">> score: 0.7603 for document #29: Fruit dishes are those that us...\n",
            ">> score: 0.7505 for document #17: We are one of the leading orga...\n",
            ">> score: 0.7265 for document #0: Fresh Pomegranate from Anushka...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 568/568 [00:16<00:00, 34.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "query: ['healthy', 'foods', 'canada']\n",
            ">> score: 0.9388 for document #10: Canada's Food Guide is a nutri...\n",
            ">> score: 0.6835 for document #9: In nutrition, the diet of an o...\n",
            ">> score: 0.5887 for document #31: A fruit serving bowl is a roun...\n",
            ">> score: 0.5879 for document #16: Anushka Avni International (AA...\n",
            ">> score: 0.5269 for document #0: Fresh Pomegranate from Anushka...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretation of GloVE results:\n",
        "\n",
        "1. GloVe matches all documents with varying similarity scores based on semantic closeness.\n",
        "\n",
        "2. TF-IDF more strongly matches one of the documents compared to the rest, but may not recognize semantic relationships with \"fruit\" and \"apples\".\n",
        "\n",
        "3. TF-IDF is more efficient to compute, and would be good with domain-specific term matching, or traditional search engines with exact keyword-based queries.\n",
        "\n",
        "4. In this way GloVe feels better when working with small datasets where capturing semantic relationships is important such as semantic search applications."
      ],
      "metadata": {
        "id": "VyJ9wa60Kbbx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8at07gGAI-MH"
      },
      "source": [
        "# Experiment 3: BERT Model\n",
        "***\n",
        "Use a BERT model obtain sentence embeddings and calculate the similarity between queries and documents.\n",
        "\n",
        "> Hint: see the Module 07 jupyter notebook for examples of how to work with BERT."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT7Y5NIhQlvJ",
        "outputId": "150890f5-060f-4683-fc03-6321b24bf882"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBSozs_tYFjg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "978b9946-0b91-4620-86be-7a82b9d6c3c5"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raaQrNXUKL2o"
      },
      "source": [
        "# for each query, output the similarity scores for the top 5 documents with\n",
        "# th highest score, and interpret your results"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLH7jBj4KL7E"
      },
      "source": [
        "# compute embeddings for queries and documents\n",
        "query_embeddings = model.encode(queries, convert_to_tensor=True)\n",
        "document_embeddings = model.encode(documents, convert_to_tensor=True)\n",
        "\n",
        "# compute cosine similarity\n",
        "cosine_scores = util.cos_sim(query_embeddings, document_embeddings)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "queries = ['fruits', 'vegetables', 'healthy foods in Canada']\n",
        "\n",
        "# find top 5 documents for each query by similarity score\n",
        "for i, query in enumerate(queries):\n",
        "\n",
        "    # get similarity scores for the current query\n",
        "    scores = cosine_scores[i]\n",
        "    # get top 5 scores\n",
        "    top_results = torch.topk(scores, k=5)\n",
        "\n",
        "    print(f\"query: {query}\")\n",
        "    for index, score in zip(top_results.indices, top_results.values):\n",
        "        print(f\">> score: {score.item():.4f} for document #{index}: {documents[index][:30]}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npEn1mzATWP8",
        "outputId": "eff990d7-7751-47d1-9080-fa88f4af0760"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query: fruits\n",
            ">> score: 0.6041 for document #6: To a botanist, a fruit is an e\n",
            ">> score: 0.5436 for document #29: Fruit dishes are those that us\n",
            ">> score: 0.4571 for document #18: Fresh Tomatoes from Anushka Av\n",
            ">> score: 0.4364 for document #31: A fruit serving bowl is a roun\n",
            ">> score: 0.4042 for document #23: Flame / Red seedless grapesFla\n",
            "\n",
            "query: vegetables\n",
            ">> score: 0.4787 for document #6: To a botanist, a fruit is an e\n",
            ">> score: 0.4280 for document #29: Fruit dishes are those that us\n",
            ">> score: 0.3915 for document #18: Fresh Tomatoes from Anushka Av\n",
            ">> score: 0.3826 for document #17: We are one of the leading orga\n",
            ">> score: 0.3549 for document #8: Nutrients are substances used \n",
            "\n",
            "query: healthy foods in Canada\n",
            ">> score: 0.6388 for document #10: Canada's Food Guide is a nutri\n",
            ">> score: 0.3855 for document #12: Canadian Industry Statistics (\n",
            ">> score: 0.3480 for document #18: Fresh Tomatoes from Anushka Av\n",
            ">> score: 0.3017 for document #29: Fruit dishes are those that us\n",
            ">> score: 0.2463 for document #8: Nutrients are substances used \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Technique Comparison\n",
        " ***\n",
        "\n",
        "Compare all three techniques and interpret your findings. Do your best to explain the differences you observe in terms of concepts learned in class (not just the what, but also the how and why one technique produces different results from another).\n"
      ],
      "metadata": {
        "id": "XpX8H6_TEPOM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## TF-IDF\n",
        "\n",
        "1. Overall, TF-IDF prioritized matching exact terms between the query and the document\n",
        " - It did not capture semantic similarity well; synonyms or related terms are treated as unrelated\n",
        " - This would require us to do some preprocessing such as lemmatization to take it into account\n",
        " - Shorter, keyword-rich documents tend to perform better because their TF-IDF scores emphasize those terms\n",
        " - TF-IDF is more efficient to compute, and would be good with domain-specific term matching, or traditional search engines with exact keyword-based queries.\n",
        "\n",
        "## GloVe\n",
        "\n",
        "2. GloVe did capture semantic relationships between words, for example: \"apple\" and \"fruit\" in similar embeddings\n",
        " - This led to better performance for queries with synonyms or related terms.\n",
        " - For example: queries like \"fruits\" match documents with semantically related words like \"apple\" or \"appricots\"\n",
        " - GloVe feels better when working with small datasets where capturing semantic relationships is important such as semantic search applications.\n",
        "\n",
        "## BERT\n",
        "\n",
        "3. BERT captured semantic and contextual relationships, making surprisingly good for ambiguous queries.\n",
        "- Strong performance for long and complex queries such as \"healthy foods in Canada\" because it can understand the relationships between all words in a query and document\n",
        "- Queries like \"vegetables\" match not only semantically similar words but also related contexts, for example: it gave document #6: \"To a botanist, a fruit is...\" the highest score: 0.4787, despite not appearing in the document — whereas TF-IDF and GloVe only VERY STRICTLY matched document #10: \"Canada's Food Guide...\"\n"
      ],
      "metadata": {
        "id": "qUaGHVgzWf18"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LwKekAZX1kDj"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}